cpu-bind=MASK - n2gpu1213, task  0  0 [181149]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 2 --nnodes 4 --rdzv_id=1234 --rdzv_endpoint n2gpu1213:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 2 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 2 --hidden-size 8 --num-attention-heads 2 --seq-length 512 --max-position-embeddings 512 --micro-batch-size 1 --global-batch-size 64 --train-samples 10_000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --lr-warmup-samples 5 --min-lr 1e-6 --lr-decay-style cosine --lr-decay-samples 12 --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 100 --log-interval 10 --save-interval 50 --eval-interval 100 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-dist --load checkpoints/gpt2-dist --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --zero-stage 1 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1231, task  3  0 [55672]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||-B------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1218, task  1  0 [290470]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1220, task  2  0 [325996]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||-----B--|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1213, task  0  0 [181263]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[default1]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default1]:WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
[default0]:pretrain_gpt.py main
[default0]:using world size: 8, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  abort_on_unmet_fused_kernel_constraints ......... False
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  bert_binary_head ................................ True
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  clip_grad ....................................... 1.0
[default0]:  codecarbon_dir .................................. None
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  curriculum_learning ............................. False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_size .............................. 4
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distributed_backend ............................. nccl
[default0]:  embed_layernorm ................................. False
[default0]:  embedding_path .................................. None
[default0]:  encoder_seq_length .............................. 512
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 100
[default0]:  eval_iters ...................................... 10
[default0]:  eval_only ....................................... None
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 100
[default0]:  ffn_hidden_size ................................. 32
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  gigaflos_no_embeds .............................. 0
[default0]:  global_batch_size ............................... 64
[default0]:  glu_activation .................................. None
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 8
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_dim ......................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  kill_switch_path ................................ None
[default0]:  kv_channels ..................................... 4
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-dist
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 10
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_level ....................................... None
[default0]:  log_level_replica ............................... None
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_params_norm ................................. False
[default0]:  log_path ........................................ None
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  loss_on_targets_only ............................ False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ 12
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 5
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_prob ....................................... 0.15
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 512
[default0]:  mean_noise_span_length .......................... None
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mmap_warmup ..................................... False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  noise_density ................................... None
[default0]:  num_attention_heads ............................. 2
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_layers ...................................... 2
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  override_lr_scheduler ........................... False
[default0]:  pad_vocab_size_to ............................... None
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  position_embedding_type ......................... PositionEmbeddingType.absolute
[default0]:  pp_partition_method ............................. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  rank ............................................ 0
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  reweight_loss_based_on_position_frequency ....... False
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-dist
[default0]:  save_interval ................................... 50
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 512
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train_iteration_range ...................... None
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  sync_tp_duplicated_parameters ................... False
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 2
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  test_weighted_split_names ....................... None
[default0]:  test_weighted_split_paths ....................... None
[default0]:  test_weighted_split_paths_path .................. None
[default0]:  test_weighted_split_splits ...................... None
[default0]:  test_weighted_split_weights ..................... None
[default0]:  tile_factor ..................................... 1
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_name_or_path .......................... None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  train_iters ..................................... None
[default0]:  train_samples ................................... 10000
[default0]:  train_tokens .................................... None
[default0]:  train_weighted_split_paths ...................... None
[default0]:  train_weighted_split_paths_path ................. None
[default0]:  universal_checkpoint ............................ False
[default0]:  use_bnb_optimizer ............................... False
[default0]:  use_checkpoint_lr_scheduler ..................... False
[default0]:  use_contiguous_buffers_in_ddp ................... False
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  valid_num_workers ............................... 2
[default0]:  valid_weighted_split_names ...................... None
[default0]:  valid_weighted_split_paths ...................... None
[default0]:  valid_weighted_split_paths_path ................. None
[default0]:  valid_weighted_split_splits ..................... None
[default0]:  valid_weighted_split_weights .................... None
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  weight_decay .................................... 0.1
[default0]:  world_size ...................................... 8
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 1
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 16
[default0]:> building GPT2BPETokenizer tokenizer ...
[default1]:pretrain_gpt.py main
[default0]: > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=2fea893 git_branch=main ****
[default0]:> initializing torch distributed ...
[default0]:[2023-04-21 08:54:17,213] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default1]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default1]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default1]:rank>0 waiting for rank 0 before loading kernels
[default0]:> setting random seeds to 42 ...
[default0]:[2023-04-21 08:55:43,314] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 2.237 seconds
[default0]:WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module fused_mix_prec_layer_norm_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module fused_mix_prec_layer_norm_cuda...
[default0]:rank 0 finished kernel load
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.81<0>
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.88<0>
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.86<0>
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.99<0>
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.99<0>
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.88<0>
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.88<0>
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO Using network IB
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.88<0>
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO Using network IB
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.99<0>
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO Using network IB
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.99<0>
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO Using network IB
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.81<0>
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO Using network IB
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.86<0>
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO Using network IB
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.86<0>
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO Using network IB
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Trees [0] 3/-1/-1->2->5 [1] 3/0/-1->2->6
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 00/0 : 1[c4000] -> 2[3000] [receive] via NET/IB/1
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Trees [0] 2/-1/-1->5->4 [1] -1/-1/-1->5->4
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 00/0 : 3[44000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 01/0 : 3[44000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 00 : 4[3000] -> 5[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 00/0 : 5[84000] -> 6[44000] [receive] via NET/IB/0
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Channel 00/0 : 3[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 01/0 : 1[c4000] -> 2[3000] [receive] via NET/IB/1
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 00 : 2[3000] -> 3[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 01 : 2[3000] -> 3[44000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 01 : 4[3000] -> 5[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 01/0 : 5[84000] -> 6[44000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 00 : 6[44000] -> 7[84000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Channel 01/0 : 3[44000] -> 4[3000] [send] via NET/IB/1
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Channel 00/0 : 5[84000] -> 6[44000] [send] via NET/IB/0
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Channel 00/0 : 7[84000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 01 : 6[44000] -> 7[84000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Channel 01/0 : 5[84000] -> 6[44000] [send] via NET/IB/0
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Channel 01/0 : 7[84000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Connected all rings
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[44000] [send] via NET/IB/0
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Connected all rings
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Channel 01/0 : 4[3000] -> 3[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Channel 00 : 3[44000] -> 2[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Channel 01 : 3[44000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 00/0 : 0[44000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[44000] [send] via NET/IB/0
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[44000] [receive] via NET/IB/1
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 01/0 : 6[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 00/0 : 7[84000] -> 0[44000] [receive] via NET/IB/1
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO Channel 00/0 : 1[c4000] -> 2[3000] [send] via NET/IB/1
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO Channel 01/0 : 1[c4000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 01/0 : 7[84000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 00 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 01 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Channel 00 : 7[84000] -> 6[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Channel 01 : 7[84000] -> 6[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 01/0 : 0[44000] -> 2[3000] [receive] via NET/IB/1
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 01/0 : 0[44000] -> 2[3000] [send] via NET/IB/1
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO Channel 00 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO Channel 01 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 00/0 : 0[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [send] via NET/IB/1
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 01/0 : 6[44000] -> 2[3000] [receive] via NET/IB/1
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[44000] [send] via NET/IB/1
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 00/0 : 6[44000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Channel 00/0 : 6[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [receive] via NET/IB/1
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Channel 00 : 5[84000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Channel 01 : 5[84000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[44000] [send] via NET/IB/1
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1231:55692:55929 [1] NCCL INFO comm 0x14ac440090d0 rank 7 nranks 8 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:55691:55926 [0] NCCL INFO comm 0x15095c0090d0 rank 6 nranks 8 cudaDev 0 busId 44000 - Init COMPLETE
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[44000] [send] via NET/IB/0
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1220:326019:326222 [1] NCCL INFO comm 0x14f90c0090d0 rank 5 nranks 8 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:326018:326220 [0] NCCL INFO comm 0x1512d00090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO Connected all trees
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1213:181296:182057 [1] NCCL INFO comm 0x152ec40090d0 rank 1 nranks 8 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1213:181295:182054 [0] NCCL INFO comm 0x145c240090d0 rank 0 nranks 8 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:290492:290868 [0] NCCL INFO comm 0x14b8300090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default1]:n2gpu1218:290493:290865 [1] NCCL INFO comm 0x14720c0090d0 rank 3 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default0]:barrier after loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default1]:barrier after loading kernels
[default0]:barrier after loading kernels
[default1]:barrier after loading kernels
[default0]:barrier after loading kernels
[default1]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 85.973 seconds
[default0]:time to initialize megatron (seconds): 841.837
[default0]:[after megatron is initialized] datetime: 2023-04-21 08:57:13 
[default0]:building GPT model ...
[default0]:[2023-04-21 08:57:15,095] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-04-21 08:57:15,096] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 08:57:15,096] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 24.52 GB, percent = 4.9%
[default0]:SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
[default0]:Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=1, model=0): 2, ProcessCoord(pipe=0, data=1, model=1): 3, ProcessCoord(pipe=0, data=2, model=0): 4, ProcessCoord(pipe=0, data=2, model=1): 5, ProcessCoord(pipe=0, data=3, model=0): 6, ProcessCoord(pipe=0, data=3, model=1): 7}
[default0]:[2023-04-21 08:57:27,908] [INFO] [module.py:358:_partition_layers] Partitioning pipeline stages with method type:transformer
[default0]:stage=0 layers=9
[default0]:     0: _to_float16
[default0]:     1: EmbeddingPipe
[default0]:     2: <lambda>
[default0]:     3: ParallelTransformerLayerPipe
[default0]:     4: ParallelTransformerLayerPipe
[default0]:     5: undo
[default0]:     6: MixedFusedLayerNorm
[default0]:     7: EmbeddingPipe
[default0]:     8: float16_to_fp32
[default0]:  loss: CrossEntropy
[default0]:[2023-04-21 08:57:27,947] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-04-21 08:57:27,947] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 08:57:27,948] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 24.65 GB, percent = 4.9%
[default0]:setting training iterations to 156
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-04-21 08:57:27,948] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Trees [0] 1/3/-1->2->0 [1] -1/-1/-1->2->1
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 1/-1/-1->3->-1
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 00/02 :    0   1   2   3
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 01/02 :    0   1   2   3
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Trees [0] 1/3/-1->2->0 [1] -1/-1/-1->2->1
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 00/0 : 3[44000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[44000] [receive] via NET/IB/1
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[44000] [receive] via NET/IB/1
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 00/0 : 3[84000] -> 0[c4000] [receive] via NET/IB/1
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 00/0 : 1[44000] -> 2[84000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[44000] [send] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 00/0 : 0[c4000] -> 1[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 01/0 : 0[c4000] -> 1[44000] [receive] via NET/IB/1
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 00/0 : 3[44000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 00/0 : 0[44000] -> 1[3000] [send] via NET/IB/1
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 01/0 : 3[84000] -> 0[c4000] [receive] via NET/IB/1
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 01/0 : 1[44000] -> 2[84000] [receive] via NET/IB/0
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 00/0 : 2[84000] -> 3[84000] [send] via NET/IB/0
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[44000] [send] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 00/0 : 1[44000] -> 2[84000] [send] via NET/IB/1
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 01/0 : 3[44000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 01/0 : 0[44000] -> 1[3000] [send] via NET/IB/1
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 00/0 : 0[c4000] -> 1[44000] [send] via NET/IB/1
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 01/0 : 0[c4000] -> 1[44000] [send] via NET/IB/1
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 01/0 : 2[84000] -> 3[84000] [send] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 01/0 : 1[44000] -> 2[84000] [send] via NET/IB/1
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 00/0 : 2[84000] -> 3[84000] [receive] via NET/IB/0
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 01/0 : 2[84000] -> 3[84000] [receive] via NET/IB/0
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 00/0 : 3[84000] -> 0[c4000] [send] via NET/IB/0
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 01/0 : 3[84000] -> 0[c4000] [send] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 01/0 : 3[84000] -> 1[44000] [receive] via NET/IB/1
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 00/0 : 2[84000] -> 0[c4000] [receive] via NET/IB/1
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 00/0 : 0[c4000] -> 2[84000] [receive] via NET/IB/0
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 01/0 : 1[44000] -> 3[84000] [receive] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 01/0 : 1[44000] -> 3[84000] [send] via NET/IB/1
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 00/0 : 0[c4000] -> 2[84000] [send] via NET/IB/1
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 01/0 : 3[84000] -> 1[44000] [send] via NET/IB/0
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 00/0 : 2[84000] -> 0[c4000] [send] via NET/IB/0
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 00/0 : 0[44000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 01/0 : 0[44000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 00/0 : 3[84000] -> 2[84000] [receive] via NET/IB/0
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 00/0 : 2[84000] -> 1[44000] [send] via NET/IB/0
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Channel 00/0 : 3[84000] -> 2[84000] [send] via NET/IB/0
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Channel 01/0 : 1[44000] -> 0[c4000] [receive] via NET/IB/1
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Channel 01/0 : 2[84000] -> 1[44000] [send] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 00/0 : 2[84000] -> 1[44000] [receive] via NET/IB/1
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1231:55692:55969 [1] NCCL INFO comm 0x14ac000090d0 rank 3 nranks 4 cudaDev 1 busId 84000 - Init COMPLETE
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 01/0 : 2[84000] -> 1[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Channel 01/0 : 1[44000] -> 0[c4000] [send] via NET/IB/1
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO Connected all trees
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[44000] [receive] via NET/IB/1
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1213:181296:182112 [1] NCCL INFO comm 0x152e840090d0 rank 0 nranks 4 cudaDev 1 busId c4000 - Init COMPLETE
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO Launch mode Parallel
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 01/0 : 3[44000] -> 1[3000] [send] via NET/IB/1
[default1]:n2gpu1220:326019:326268 [1] NCCL INFO comm 0x14f8cc0090d0 rank 2 nranks 4 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 00/0 : 0[44000] -> 2[3000] [receive] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 00/0 : 0[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 01/0 : 3[44000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[44000] [send] via NET/IB/0
[default1]:n2gpu1218:290493:290907 [1] NCCL INFO comm 0x1471c80090d0 rank 1 nranks 4 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 00/0 : 3[44000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Channel 00/0 : 3[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:55691:55970 [0] NCCL INFO comm 0x1509200090d0 rank 3 nranks 4 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[44000] [send] via NET/IB/0
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:290492:290908 [0] NCCL INFO comm 0x14b7ec0090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:326018:326269 [0] NCCL INFO comm 0x15128c0090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1213:181295:182114 [0] NCCL INFO comm 0x145bd80090d0 rank 0 nranks 4 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO Launch mode Parallel
[default0]:[2023-04-21 08:57:35,437] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-04-21 08:57:35,437] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-04-21 08:57:35,437] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2023-04-21 08:57:35,438] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-04-21 08:57:35,438] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-04-21 08:57:35,438] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[default0]:[2023-04-21 08:57:35,438] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[default0]:[2023-04-21 08:57:35,438] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[default0]:[2023-04-21 08:57:35,438] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-04-21 08:57:35,438] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Time to load utils op: 2.806636333465576 seconds
[default1]:Rank: 5 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 9.633434057235718 seconds
[default1]:Rank: 1 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 7.716533660888672 seconds
[default0]:Rank: 0 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Loading extension module utils...
[default0]:Time to load utils op: 11.605159521102905 seconds
[default0]:Rank: 4 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default1]:Time to load utils op: 14.120014905929565 seconds
[default1]:Rank: 7 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 11.720840215682983 seconds
[default0]:Rank: 6 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 13.609705209732056 seconds
[default0]:Rank: 2 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default1]:Time to load utils op: 15.344244956970215 seconds
[default1]:Rank: 3 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.004040718078613281 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.06531453132629395 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0036728382110595703 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.022097349166870117 seconds
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:[2023-04-21 08:57:50,054] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-04-21 08:57:50,062] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 08:57:50,062] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 25.66 GB, percent = 5.1%
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 00 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 00 : 0[3000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 01 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 02 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 01 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 02 : 0[3000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 03 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 03 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 00 : 0[44000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 01 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 00 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 04 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 05 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 04 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 05 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 02 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 01 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 02 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 06 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Channel 07 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 03 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 03 : 1[84000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 06 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Channel 07 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 04 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 04 : 1[84000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 05 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 05 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 06 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1220:326019:326286 [1] NCCL INFO comm 0x14f8b80090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:326018:326285 [0] NCCL INFO comm 0x1512780090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 06 : 0[44000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Channel 07 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Channel 07 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1231:55692:55979 [1] NCCL INFO comm 0x14abfc0090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1231:55691:55978 [0] NCCL INFO comm 0x1509100090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO Launch mode Parallel
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.004096269607543945 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.004565000534057617 seconds
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1218:290492:290916 [0] NCCL INFO comm 0x14b7e80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1218:290493:290917 [1] NCCL INFO comm 0x1471c40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.034477949142456055 seconds
[default0]:[2023-04-21 08:57:58,016] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-04-21 08:57:58,673] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 08:57:58,673] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 26.39 GB, percent = 5.2%
[default0]:[2023-04-21 08:57:58,673] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[default0]:[2023-04-21 08:57:58,696] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-04-21 08:57:58,697] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 08:57:58,697] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 26.39 GB, percent = 5.2%
[default0]:[2023-04-21 08:57:58,697] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-04-21 08:57:58,697] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-04-21 08:57:58,697] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x145c977c39d0>
[default0]:[2023-04-21 08:57:58,697] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   amp_enabled .................. False
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   amp_params ................... False
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-04-21 08:57:58,698] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x145c977fd0f0>
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   communication_data_type ...... None
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   disable_allgather ............ False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   dump_state ................... False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-04-21 08:57:58,699] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   fp16_enabled ................. True
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   global_rank .................. 0
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 16
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[default0]:[2023-04-21 08:57:58,700] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 4096
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   loss_scale ................... 0
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   memory_breakdown ............. False
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   optimizer_name ............... None
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   optimizer_params ............. None
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   pld_enabled .................. False
[default0]:[2023-04-21 08:57:58,718] [INFO] [config.py:957:print]   pld_params ................... False
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   prescale_gradients ........... False
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   scheduler_name ............... None
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   scheduler_params ............. None
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   sparse_attention ............. None
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   steps_per_print .............. 2000
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   train_batch_size ............. 64
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   world_size ................... 4
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   zero_enabled ................. True
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:957:print]   zero_optimization_stage ...... 1
[default0]:[2023-04-21 08:57:58,719] [INFO] [config.py:943:print_user_config]   json = {
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "train_batch_size": 64, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 1
[default0]:    }, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 12
[default0]:    }, 
[default0]:    "steps_per_print": 2.000000e+03, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0009036064147949219 seconds
[default0]:[2023-04-21 08:57:58,721] [INFO] [engine.py:81:__init__] CONFIG: micro_batches=16 micro_batch_size=1
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 00 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 01 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 02 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 03 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 04 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 05 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 06 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Channel 07 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 01 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 02 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 03 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 04 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 05 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 06 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Channel 07 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO Connected all trees
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1213:181296:182222 [1] NCCL INFO comm 0x152e7c0090d0 rank 1 nranks 2 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1213:181295:182221 [0] NCCL INFO comm 0x145bd00090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO Launch mode Parallel
[default0]:[2023-04-21 08:58:02,690] [INFO] [engine.py:136:__init__] RANK=0 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=206760 (0.207M) TOTAL_PARAMS=413520 (0.414M) UNIQUE_PARAMS=413520 (0.414M)
[default1]:[2023-04-21 08:58:02,715] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-21 08:58:02,715] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-21 08:58:02,715] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-21 08:58:02,726] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-21 08:58:02,715] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-21 08:58:02,714] [INFO] [engine.py:136:__init__] RANK=1 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=206760 (0.207M) TOTAL_PARAMS=413520 (0.414M) UNIQUE_PARAMS=413520 (0.414M)
[default1]:[2023-04-21 08:58:02,714] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-21 08:58:02,739] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file checkpoints/gpt2-dist 
[default0]:    will not load any checkpoints and will start from random
[default1]:time (ms) | load-checkpoint: 153.69
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/utils.py:349: UserWarning: Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings
[default0]:  warnings.warn("Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings")
[default0]:estimated model parameters: 0.00041352
[default0]:estimated model parameters without embeddings: 1.872e-06
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-04-21 08:58:05 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      10000
[default0]:    validation: 1280
[default0]:    test:       640
[default0]:> building train, validation, and test datasets for GPT ...
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.221754 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9690) total of 9690 documents
[default0]:    validation:
[default0]:     document indices in [9690, 9990) total of 300 documents
[default0]:    test:
[default0]:     document indices in [9990, 10000) total of 10 documents
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 1/-1/-1->3->-1
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 00/0 : 3[44000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Trees [0] 1/3/-1->2->0 [1] -1/-1/-1->2->1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[44000] [receive] via NET/IB/1
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[44000] [receive] via NET/IB/1
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 00/0 : 0[44000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 01/0 : 3[44000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 00/0 : 0[44000] -> 1[3000] [send] via NET/IB/1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[44000] [send] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 00/0 : 3[44000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 01/0 : 0[44000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 01/0 : 0[44000] -> 1[3000] [send] via NET/IB/1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[44000] [send] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 01/0 : 3[44000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 00/0 : 0[44000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 00/0 : 0[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[44000] [receive] via NET/IB/1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[44000] [send] via NET/IB/0
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 01/0 : 3[44000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 01/0 : 3[44000] -> 1[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[44000] [send] via NET/IB/0
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[44000] [receive] via NET/IB/1
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 00/0 : 3[44000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Channel 00/0 : 3[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:55691:55989 [0] NCCL INFO comm 0x1509040090d0 rank 3 nranks 4 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[44000] [send] via NET/IB/0
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1213:181295:182228 [0] NCCL INFO comm 0x145bc80090d0 rank 0 nranks 4 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:326018:326292 [0] NCCL INFO comm 0x1512700090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:290492:290924 [0] NCCL INFO comm 0x14b7d80090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1218:290492:290929 [0] NCCL INFO comm 0x14b7d40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1231:55691:55994 [0] NCCL INFO comm 0x1509000090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1213:181295:182233 [0] NCCL INFO comm 0x145bc40090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_shuffle_idx.npy
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1220:326018:326297 [0] NCCL INFO comm 0x15126c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:    loaded indexed file in 0.081 seconds
[default0]:    total number of samples: 56335
[default0]:    total number of epochs: 1
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_1280ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_1280ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_1280ns_512sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.047 seconds
[default0]:    total number of samples: 1830
[default0]:    total number of epochs: 1
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_512sl_42s_doc_idx.npy
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 00 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 00 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 01 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 00 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 00 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 01 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 01 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 02 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 03 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 01 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 02 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 02 : 0[44000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 03 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 04 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 02 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 03 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 03 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_512sl_42s_sample_idx.npy
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 05 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 06 : 1[84000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 04 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 04 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 05 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 04 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Channel 07 : 1[84000] -> 0[44000] via P2P/IPC/read
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 05 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 06 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Channel 07 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 05 : 0[44000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 06 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Channel 07 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 06 : 0[44000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Channel 07 : 0[44000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1220:326019:326302 [1] NCCL INFO comm 0x14f8b00090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:326018:326301 [0] NCCL INFO comm 0x1512540090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1231:55691:55998 [0] NCCL INFO comm 0x1508e80090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1231:55692:55999 [1] NCCL INFO comm 0x14abf40090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Init COMPLETE
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_512sl_42s_shuffle_idx.npy
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:    loaded indexed file in 4.250 seconds
[default0]:    total number of samples: 700
[default0]:    total number of epochs: 11
[default0]:> finished creating GPT datasets ...
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1218:290493:290934 [1] NCCL INFO comm 0x1471bc0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1218:290492:290933 [0] NCCL INFO comm 0x14b7b80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 00 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 00 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 01 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 01 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 02 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 02 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 03 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 04 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 03 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 05 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 04 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 06 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 05 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 06 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Channel 07 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Channel 07 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO Connected all trees
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1213:181296:182238 [1] NCCL INFO comm 0x152e740090d0 rank 1 nranks 2 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:n2gpu1213:181295:182237 [0] NCCL INFO comm 0x145bac0090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO Launch mode Parallel
[default1]:time (ms) | model-and-optimizer-setup: 48999.05 | train/valid/test-data-iterators-setup: 6101.73
[default0]:[after dataloaders are built] datetime: 2023-04-21 08:58:20 
[default0]:done with setup ...
[default0]:training ...
[default0]:Number of parameters: [tensor rank - pipeline rank] w/ and w/o embeddings:
[default0]:[000-000] 0.0004B / 0.0000B
[default1]:[001-000] 0.0004B / 0.0000B
[default0]:[before the start of training step] datetime: 2023-04-21 08:58:20 
[default0]:[2023-04-21 08:58:20,837] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[default0]:[2023-04-21 08:58:20,837] [INFO] [checkpointing.py:530:forward] ----Partition Activations True, CPU CHECKPOINTING False
[default0]:[2023-04-21 08:58:20,837] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 2 total layers
[default0]:[2023-04-21 08:58:20,837] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[default0]:[2023-04-21 08:58:20,837] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[default1]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Connected all rings
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO Connected all trees
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1213:181296:182663 [1] NCCL INFO comm 0x152e280090d0 rank 0 nranks 1 cudaDev 1 busId c4000 - Init COMPLETE
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1231:55692:56420 [1] NCCL INFO comm 0x14aba80090d0 rank 0 nranks 1 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1218:290492:291354 [0] NCCL INFO comm 0x14b7400090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1218:290493:291355 [1] NCCL INFO comm 0x14716c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1231:55691:56418 [0] NCCL INFO comm 0x1508700090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1220:326019:326725 [1] NCCL INFO comm 0x14f8740090d0 rank 0 nranks 1 cudaDev 1 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1220:326018:326723 [0] NCCL INFO comm 0x1511e00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Connected all rings
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO Connected all trees
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1213:181295:182665 [0] NCCL INFO comm 0x145b340090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default1]: iteration       10/     156 | consumed samples:          640 | consumed tokens:       327680 | elapsed time per iteration (s): 10.58 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082923E+01 | loss scale: 4096.0 | grad norm: 0.278 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.049 | TFLOPs: 0.00 |
[default1]: iteration       20/     156 | consumed samples:         1280 | consumed tokens:       655360 | elapsed time per iteration (s): 9.30 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082914E+01 | loss scale: 4096.0 | grad norm: 0.274 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.878 | TFLOPs: 0.00 |
[default1]: iteration       30/     156 | consumed samples:         1920 | consumed tokens:       983040 | elapsed time per iteration (s): 8.99 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082926E+01 | loss scale: 4096.0 | grad norm: 0.276 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 7.118 | TFLOPs: 0.00 |
[default1]: iteration       40/     156 | consumed samples:         2560 | consumed tokens:      1310720 | elapsed time per iteration (s): 8.43 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082896E+01 | loss scale: 4096.0 | grad norm: 0.284 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 7.596 | TFLOPs: 0.00 |
[default1]: iteration       50/     156 | consumed samples:         3200 | consumed tokens:      1638400 | elapsed time per iteration (s): 8.57 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082906E+01 | loss scale: 4096.0 | grad norm: 0.289 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 7.466 | TFLOPs: 0.00 |
[default0]:saving checkpoint at iteration      50 to checkpoints/gpt2-dist
[default0]:[2023-04-21 09:05:59,849] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!
[default0]:[2023-04-21 09:05:59,937] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_01-model_00-model_states.pt...
[default0]:[2023-04-21 09:05:59,940] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_01-model_00-model_states.pt.
[default0]:[2023-04-21 09:05:59,941] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_03-model_00-model_states.pt...
[default0]:[2023-04-21 09:05:59,943] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_03-model_00-model_states.pt.
[default0]:[2023-04-21 09:05:59,944] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_04-model_00-model_states.pt...
[default0]:[2023-04-21 09:05:59,946] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_04-model_00-model_states.pt.
[default0]:[2023-04-21 09:05:59,946] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_06-model_00-model_states.pt...
[default0]:[2023-04-21 09:05:59,951] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_06-model_00-model_states.pt.
[default0]:[2023-04-21 09:05:59,951] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-dist/global_step50/mp_rank_00_model_states.pt
[default0]:[2023-04-21 09:05:59,951] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/mp_rank_00_model_states.pt...
[default0]:[2023-04-21 09:05:59,955] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/mp_rank_00_model_states.pt.
[default1]:[2023-04-21 09:06:00,751] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_01-model_01-model_states.pt.
[default1]:[2023-04-21 09:06:00,752] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_03-model_01-model_states.pt...
[default1]:[2023-04-21 09:06:00,755] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_03-model_01-model_states.pt.
[default1]:[2023-04-21 09:06:00,756] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_04-model_01-model_states.pt...
[default1]:[2023-04-21 09:06:00,758] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_04-model_01-model_states.pt.
[default1]:[2023-04-21 09:06:00,758] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_06-model_01-model_states.pt...
[default1]:[2023-04-21 09:06:00,760] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_06-model_01-model_states.pt.
[default1]:[2023-04-21 09:06:00,760] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: checkpoints/gpt2-dist/global_step50/mp_rank_01_model_states.pt
[default1]:[2023-04-21 09:06:00,760] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/mp_rank_01_model_states.pt...
[default1]:[2023-04-21 09:06:00,762] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/mp_rank_01_model_states.pt.
[default1]:[2023-04-21 09:06:01,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:06:01,082] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:06:01,082] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:06:01,082] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-21 09:06:01,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-04-21 09:06:01,087] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:06:01,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default0]:[2023-04-21 09:06:01,063] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:06:01,063] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:06:01,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-21 09:06:01,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:06:01,073] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:06:01,073] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:06:01,073] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-21 09:06:01,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:06:01,112] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:06:01,112] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:06:01,112] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-21 09:06:01,058] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:06:01,063] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:06:01,063] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:06:01,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-21 09:06:01,189] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:06:01,189] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:06:01,189] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-21 09:06:01,489] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:06:01,489] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-21 09:06:01,843] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:06:01,843] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:06:01,843] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:  successfully saved checkpoint at iteration      50 to checkpoints/gpt2-dist
[default1]:time (ms) | save-checkpoint: 3079.83
[default1]: iteration       60/     156 | consumed samples:         3840 | consumed tokens:      1966080 | elapsed time per iteration (s): 10.69 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082919E+01 | loss scale: 4096.0 | grad norm: 0.266 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.989 | TFLOPs: 0.00 |
[default1]: iteration       70/     156 | consumed samples:         4480 | consumed tokens:      2293760 | elapsed time per iteration (s): 10.17 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082943E+01 | loss scale: 4096.0 | grad norm: 0.273 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.290 | TFLOPs: 0.00 |
[default1]: iteration       80/     156 | consumed samples:         5120 | consumed tokens:      2621440 | elapsed time per iteration (s): 8.09 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082930E+01 | loss scale: 4096.0 | grad norm: 0.300 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 7.914 | TFLOPs: 0.00 |
[default1]: iteration       90/     156 | consumed samples:         5760 | consumed tokens:      2949120 | elapsed time per iteration (s): 9.20 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082894E+01 | loss scale: 4096.0 | grad norm: 0.272 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.954 | TFLOPs: 0.00 |
[default1]: iteration      100/     156 | consumed samples:         6400 | consumed tokens:      3276800 | elapsed time per iteration (s): 8.95 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082876E+01 | loss scale: 4096.0 | grad norm: 0.281 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 7.150 | TFLOPs: 0.00 |
[default1]:-----------------------------------------------------------------------------------------
[default1]:valid loss at iteration 100 | lm loss value: 1.082929E+01 | lm loss PPL: 5.047787E+04 | 
[default1]:-----------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     100 to checkpoints/gpt2-dist
[default0]:[2023-04-21 09:14:12,246] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[default0]:[2023-04-21 09:14:12,368] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_01-model_00-model_states.pt...
[default0]:[2023-04-21 09:14:12,372] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_01-model_00-model_states.pt.
[default0]:[2023-04-21 09:14:12,372] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_03-model_00-model_states.pt...
[default0]:[2023-04-21 09:14:12,376] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_03-model_00-model_states.pt.
[default0]:[2023-04-21 09:14:12,376] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_04-model_00-model_states.pt...
[default0]:[2023-04-21 09:14:12,379] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_04-model_00-model_states.pt.
[default0]:[2023-04-21 09:14:12,379] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_06-model_00-model_states.pt...
[default0]:[2023-04-21 09:14:12,382] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_06-model_00-model_states.pt.
[default0]:[2023-04-21 09:14:12,382] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-dist/global_step100/mp_rank_00_model_states.pt
[default0]:[2023-04-21 09:14:12,382] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/mp_rank_00_model_states.pt...
[default0]:[2023-04-21 09:14:12,385] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/mp_rank_00_model_states.pt.
[default1]:[2023-04-21 09:14:14,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_01-model_01-model_states.pt.
[default1]:[2023-04-21 09:14:14,708] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_03-model_01-model_states.pt...
[default1]:[2023-04-21 09:14:14,711] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_03-model_01-model_states.pt.
[default1]:[2023-04-21 09:14:14,712] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_04-model_01-model_states.pt...
[default1]:[2023-04-21 09:14:14,714] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_04-model_01-model_states.pt.
[default1]:[2023-04-21 09:14:14,714] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_06-model_01-model_states.pt...
[default1]:[2023-04-21 09:14:14,718] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_06-model_01-model_states.pt.
[default1]:[2023-04-21 09:14:14,718] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: checkpoints/gpt2-dist/global_step100/mp_rank_01_model_states.pt
[default1]:[2023-04-21 09:14:14,718] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/mp_rank_01_model_states.pt...
[default1]:[2023-04-21 09:14:14,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/mp_rank_01_model_states.pt.
[default1]:[2023-04-21 09:14:14,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:14:14,994] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:14:14,994] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:14:14,994] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2023-04-21 09:14:14,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:14:14,985] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:14:14,985] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:14:14,985] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-21 09:14:14,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default0]:[2023-04-21 09:14:14,985] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:14:14,986] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:14:14,986] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2023-04-21 09:14:14,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_01_optim_states.pt...
[default0]:[2023-04-21 09:14:14,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default1]:[2023-04-21 09:14:14,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 09:14:15,099] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:14:15,099] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:14:15,099] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-21 09:14:15,086] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:14:15,086] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:14:15,086] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2023-04-21 09:14:15,121] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 09:14:15,121] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 09:14:15,121] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-21 09:14:14,980] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-04-21 09:14:15,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:14:16,136] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 09:14:16,136] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:14:16,136] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-21 09:14:16,506] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 09:14:16,506] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:  successfully saved checkpoint at iteration     100 to checkpoints/gpt2-dist
[default1]:time (ms) | save-checkpoint: 5695.21
[default0]:[exiting program at iteration 100] datetime: 2023-04-21 09:14:16 
[default0]:n2gpu1220:326018:326225 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO comm 0x1512d00090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO comm 0x14f90c0090d0 rank 5 nranks 8 cudaDev 1 busId 84000 - Abort COMPLETE
[default0]:n2gpu1231:55691:55932 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1231:55692:55931 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO comm 0x14ac440090d0 rank 7 nranks 8 cudaDev 1 busId 84000 - Abort COMPLETE
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO comm 0x15095c0090d0 rank 6 nranks 8 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1220:326018:326287 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO comm 0x1512780090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1220:326018:326726 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO comm 0x1511e00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1220:326018:326304 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO comm 0x1512540090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1220:326018:326298 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO comm 0x15126c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1220:326018:326293 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1220:326018:326018 [0] NCCL INFO comm 0x1512700090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Abort COMPLETE
[default1]:n2gpu1220:326019:326288 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO comm 0x14f8b80090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Abort COMPLETE
[default1]:n2gpu1220:326019:326727 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO comm 0x14f8740090d0 rank 0 nranks 1 cudaDev 1 busId 84000 - Abort COMPLETE
[default1]:n2gpu1220:326019:326303 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1220:326019:326019 [1] NCCL INFO comm 0x14f8b00090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Abort COMPLETE
[default0]:n2gpu1231:55691:55980 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO comm 0x1509100090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1231:55691:56421 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO comm 0x1508700090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1231:55691:56000 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO comm 0x1508e80090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1231:55691:55995 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO comm 0x1509000090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1231:55691:55990 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:55691:55691 [0] NCCL INFO comm 0x1509040090d0 rank 3 nranks 4 cudaDev 0 busId 44000 - Abort COMPLETE
[default1]:n2gpu1231:55692:55981 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO comm 0x14abfc0090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Abort COMPLETE
[default1]:n2gpu1231:55692:56422 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO comm 0x14aba80090d0 rank 0 nranks 1 cudaDev 1 busId 84000 - Abort COMPLETE
[default1]:n2gpu1231:55692:56001 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1231:55692:55692 [1] NCCL INFO comm 0x14abf40090d0 rank 1 nranks 2 cudaDev 1 busId 84000 - Abort COMPLETE
[default0]:n2gpu1218:290492:290869 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO comm 0x14b8300090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1213:181295:182060 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO comm 0x145c240090d0 rank 0 nranks 8 cudaDev 0 busId 44000 - Abort COMPLETE
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO comm 0x14720c0090d0 rank 3 nranks 8 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1213:181296:182059 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO comm 0x152ec40090d0 rank 1 nranks 8 cudaDev 1 busId c4000 - Abort COMPLETE
[default0]:n2gpu1218:290492:290919 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO comm 0x14b7e80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:290492:291356 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO comm 0x14b7400090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:290492:290936 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO comm 0x14b7b80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:290492:290930 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO comm 0x14b7d40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:290492:290925 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1218:290493:290918 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO comm 0x1471c40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1218:290493:291357 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO comm 0x14716c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1218:290493:290935 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1218:290493:290493 [1] NCCL INFO comm 0x1471bc0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default0]:n2gpu1218:290492:290492 [0] NCCL INFO comm 0x14b7d80090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1213:181295:182223 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO comm 0x145bd00090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1213:181295:182667 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1213:181296:182224 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO comm 0x152e7c0090d0 rank 1 nranks 2 cudaDev 1 busId c4000 - Abort COMPLETE
[default1]:n2gpu1213:181296:182666 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO comm 0x152e280090d0 rank 0 nranks 1 cudaDev 1 busId c4000 - Abort COMPLETE
[default1]:n2gpu1213:181296:182239 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1213:181296:181296 [1] NCCL INFO comm 0x152e740090d0 rank 1 nranks 2 cudaDev 1 busId c4000 - Abort COMPLETE
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO comm 0x145b340090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1213:181295:182240 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO comm 0x145bac0090d0 rank 0 nranks 2 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1213:181295:182234 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO comm 0x145bc40090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Abort COMPLETE
[default0]:n2gpu1213:181295:182229 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1213:181295:181295 [0] NCCL INFO comm 0x145bc80090d0 rank 0 nranks 4 cudaDev 0 busId 44000 - Abort COMPLETE
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'n2gpu1218.ab2021.local_290470_0' has failed to send a keep-alive heartbeat to the rendezvous '1234' due to an error of type RendezvousTimeoutError.
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'n2gpu1220.ab2021.local_325996_0' has failed to shutdown the rendezvous '1234' due to an error of type RendezvousConnectionError.
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'n2gpu1231.ab2021.local_55672_0' has failed to shutdown the rendezvous '1234' due to an error of type RendezvousConnectionError.
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'n2gpu1218.ab2021.local_290470_0' has failed to shutdown the rendezvous '1234' due to an error of type RendezvousConnectionError.
