cpu-bind=MASK - n2gpu1217, task  0  0 [59237]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 4 --nnodes 4 --rdzv_id=13687 --rdzv_endpoint n2gpu1217:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 2 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 1024 --max-position-embeddings 1024 --micro-batch-size 1 --global-batch-size 512 --train-samples 500000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --min-lr 1e-6 --lr-decay-style cosine --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 1000 --log-interval 2 --save-interval 50 --eval-interval 50 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-dist-1 --load checkpoints/gpt2-dist-1 --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist-1 --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --zero-stage 1 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1217, task  0  0 [59351]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1232, task  3  0 [181471]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1222, task  1  0 [121223]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1227, task  2  0 [164786]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[default2]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  abort_on_unmet_fused_kernel_constraints ......... False
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  bert_binary_head ................................ True
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  clip_grad ....................................... 1.0
[default0]:  codecarbon_dir .................................. None
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  curriculum_learning ............................. False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_size .............................. 8
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distributed_backend ............................. nccl
[default0]:  embed_layernorm ................................. False
[default0]:  embedding_path .................................. None
[default0]:  encoder_seq_length .............................. 1024
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 50
[default0]:  eval_iters ...................................... 10
[default0]:  eval_only ....................................... None
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 1000
[default0]:  ffn_hidden_size ................................. 4096
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  gigaflos_no_embeds .............................. 0
[default0]:  global_batch_size ............................... 512
[default0]:  glu_activation .................................. None
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 1024
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_dim ......................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  kill_switch_path ................................ None
[default0]:  kv_channels ..................................... 64
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-dist-1
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 2
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_level ....................................... None
[default0]:  log_level_replica ............................... None
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_params_norm ................................. False
[default0]:  log_path ........................................ None
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  loss_on_targets_only ............................ False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 0
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_prob ....................................... 0.15
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 1024
[default0]:  mean_noise_span_length .......................... None
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mmap_warmup ..................................... False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  noise_density ................................... None
[default0]:  num_attention_heads ............................. 16
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_layers ...................................... 24
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  override_lr_scheduler ........................... False
[default0]:  pad_vocab_size_to ............................... None
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  position_embedding_type ......................... PositionEmbeddingType.absolute
[default0]:  pp_partition_method ............................. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  rank ............................................ 0
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  reweight_loss_based_on_position_frequency ....... False
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-dist-1
[default0]:  save_interval ................................... 50
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 1024
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train_iteration_range ...................... None
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  sync_tp_duplicated_parameters ................... False
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 2
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist-1
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  test_weighted_split_names ....................... None
[default0]:  test_weighted_split_paths ....................... None
[default0]:  test_weighted_split_paths_path .................. None
[default0]:  test_weighted_split_splits ...................... None
[default0]:  test_weighted_split_weights ..................... None
[default0]:  tile_factor ..................................... 1
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_name_or_path .......................... None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  train_iters ..................................... None
[default0]:  train_samples ................................... 500000
[default0]:  train_tokens .................................... None
[default0]:  train_weighted_split_paths ...................... None
[default0]:  train_weighted_split_paths_path ................. None
[default0]:  universal_checkpoint ............................ False
[default0]:  use_bnb_optimizer ............................... False
[default0]:  use_checkpoint_lr_scheduler ..................... False
[default0]:  use_contiguous_buffers_in_ddp ................... False
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  valid_num_workers ............................... 2
[default0]:  valid_weighted_split_names ...................... None
[default0]:  valid_weighted_split_paths ...................... None
[default0]:  valid_weighted_split_paths_path ................. None
[default0]:  valid_weighted_split_splits ..................... None
[default0]:  valid_weighted_split_weights .................... None
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  weight_decay .................................... 0.1
[default0]:  world_size ...................................... 16
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 1
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 64
[default0]:> building GPT2BPETokenizer tokenizer ...
[default3]:pretrain_gpt.py main
[default2]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default2]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default0]: > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default2]:pretrain_gpt.py main
[default0]:**** Git info for Megatron: git_hash=7482fcf git_branch=main ****
[default0]:> initializing torch distributed ...
[default0]:[2023-04-23 11:32:37,142] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default3]:WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
[default0]:> initializing tensor model parallel with size 2
[default0]:> initializing pipeline model parallel with size 1
[default1]:rank>0 waiting for rank 0 before loading kernels
[default3]:rank>0 waiting for rank 0 before loading kernels
[default2]:rank>0 waiting for rank 0 before loading kernels
[default3]:rank>0 waiting for rank 0 before loading kernels
[default1]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default3]:rank>0 waiting for rank 0 before loading kernels
[default1]:rank>0 waiting for rank 0 before loading kernels
[default2]:rank>0 waiting for rank 0 before loading kernels
[default3]:rank>0 waiting for rank 0 before loading kernels
[default1]:rank>0 waiting for rank 0 before loading kernels
[default2]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:> setting random seeds to 42 ...
[default0]:[2023-04-23 11:32:38,566] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default2]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 1.577 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module fused_mix_prec_layer_norm_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module fused_mix_prec_layer_norm_cuda...
[default0]:rank 0 finished kernel load
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:n2gpu1222:121251:121251 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default3]:n2gpu1222:121252:121252 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default3]:n2gpu1227:164816:164816 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default2]:n2gpu1227:164815:164815 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default3]:n2gpu1232:181496:181496 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default0]:n2gpu1222:121249:121249 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default1]:n2gpu1227:164814:164814 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default1]:n2gpu1227:164814:164814 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1227:164814:164814 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default1]:n2gpu1227:164814:164814 [1] NCCL INFO Using network IB
[default0]:n2gpu1227:164813:164813 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default0]:n2gpu1227:164813:164813 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1217:59375:59375 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default2]:n2gpu1217:59375:59375 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1232:181495:181495 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default2]:n2gpu1232:181495:181495 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1232:181495:181495 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default2]:n2gpu1232:181495:181495 [2] NCCL INFO Using network IB
[default1]:n2gpu1232:181494:181494 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default1]:n2gpu1232:181494:181494 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1222:121250:121250 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default1]:n2gpu1222:121250:121250 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1232:181493:181493 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default0]:n2gpu1232:181493:181493 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1232:181493:181493 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default0]:n2gpu1232:181493:181493 [0] NCCL INFO Using network IB
[default3]:n2gpu1232:181496:181496 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1222:121251:121251 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1222:121251:121251 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default2]:n2gpu1222:121251:121251 [2] NCCL INFO Using network IB
[default3]:n2gpu1222:121252:121252 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1222:121252:121252 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default3]:n2gpu1222:121252:121252 [3] NCCL INFO Using network IB
[default3]:n2gpu1227:164816:164816 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1227:164816:164816 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default3]:n2gpu1227:164816:164816 [3] NCCL INFO Using network IB
[default2]:n2gpu1227:164815:164815 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1222:121249:121249 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1222:121249:121249 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default0]:n2gpu1222:121249:121249 [0] NCCL INFO Using network IB
[default3]:n2gpu1217:59376:59376 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default3]:n2gpu1217:59376:59376 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1227:164813:164813 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default0]:n2gpu1227:164813:164813 [0] NCCL INFO Using network IB
[default1]:n2gpu1217:59374:59374 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default1]:n2gpu1217:59374:59374 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1217:59374:59374 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default1]:n2gpu1217:59374:59374 [1] NCCL INFO Using network IB
[default1]:n2gpu1222:121250:121250 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default1]:n2gpu1222:121250:121250 [1] NCCL INFO Using network IB
[default1]:n2gpu1232:181494:181494 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default1]:n2gpu1232:181494:181494 [1] NCCL INFO Using network IB
[default3]:n2gpu1232:181496:181496 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default3]:n2gpu1232:181496:181496 [3] NCCL INFO Using network IB
[default2]:n2gpu1227:164815:164815 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default2]:n2gpu1227:164815:164815 [2] NCCL INFO Using network IB
[default3]:n2gpu1217:59376:59376 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default3]:n2gpu1217:59376:59376 [3] NCCL INFO Using network IB
[default2]:n2gpu1217:59375:59375 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default2]:n2gpu1217:59375:59375 [2] NCCL INFO Using network IB
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/-1/-1->13->12 [3] 14/-1/-1->13->12
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->13
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] -1/-1/-1->15->14 [3] -1/-1/-1->15->14
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/8/-1->0->-1 [2] 1/-1/-1->0->4 [3] 1/-1/-1->0->4
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/4/-1->12->-1 [3] 13/4/-1->12->-1
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] -1/-1/-1->11->10 [3] -1/-1/-1->11->10
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/4/-1->9->8 [2] 10/-1/-1->9->8 [3] 10/-1/-1->9->8
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/-1/-1->10->9 [3] 11/-1/-1->10->9
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 00/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/-1/-1->4->9 [2] 5/0/-1->4->12 [3] 5/0/-1->4->12
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/8/-1->5->4 [3] 6/8/-1->5->4
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 01/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Trees [0] 9/12/-1->8->0 [1] 9/12/-1->8->0 [2] 9/-1/-1->8->5 [3] 9/-1/-1->8->5
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 00 : 13[44000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 02/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 00 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 00/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 00 : 9[44000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 00 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 01 : 13[44000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 03/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 00 : 1[44000] -> 2[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 00 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 01/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 02/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 00 : 12[3000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 01 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 01 : 12[3000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 00 : 4[3000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 01 : 9[44000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 01 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 02 : 13[44000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 01 : 1[44000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 03/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 02 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 01 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 00 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 00 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 02 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 02 : 9[44000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 02 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 02 : 1[44000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 03 : 13[44000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 03 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 01 : 4[3000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 00 : 8[3000] -> 9[44000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 02 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 03 : 12[3000] -> 13[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 01 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 02 : 4[3000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 01 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 01 : 8[3000] -> 9[44000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 03 : 9[44000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 03 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 03 : 1[44000] -> 2[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 03 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 02 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 02 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 02 : 8[3000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 03 : 4[3000] -> 5[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Connected all rings
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Connected all rings
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 03 : 5[44000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 03 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 03 : 8[3000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Connected all rings
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Connected all rings
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Connected all rings
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 00 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 00 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 00 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 00 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 01 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 00 : 13[44000] -> 12[3000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 00 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Connected all rings
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 01 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 01 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 02 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 00 : 10[84000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 01 : 14[84000] -> 13[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 02 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 02 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Channel 03 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 01 : 13[44000] -> 12[3000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 02 : 14[84000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 00 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 01 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 00 : 6[84000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 01 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 02 : 13[44000] -> 12[3000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 01 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 02 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 01 : 6[84000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Channel 03 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Channel 03 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Channel 03 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 02 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Channel 03 : 13[44000] -> 12[3000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 02 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Channel 03 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Channel 03 : 10[84000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 02 : 6[84000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Channel 03 : 2[84000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 00/0 : 8[3000] -> 0[3000] [receive] via NET/IB/1
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Channel 03 : 6[84000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 01/0 : 8[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 00/0 : 0[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 01/0 : 0[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 00/0 : 0[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 01/0 : 0[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 00/0 : 8[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 01/0 : 8[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1232:181496:181611 [3] NCCL INFO comm 0x1487040090d0 rank 15 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1232:181493:181606 [0] NCCL INFO comm 0x14eb400090d0 rank 12 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 00 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181608 [1] NCCL INFO comm 0x14f11c0090d0 rank 13 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1232:181495:181604 [2] NCCL INFO comm 0x14a4d40090d0 rank 14 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 01 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 02 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Channel 03 : 9[44000] -> 8[3000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:59373:59562 [0] NCCL INFO comm 0x148bfc0090d0 rank 0 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Launch mode Parallel
[default3]:n2gpu1217:59376:59569 [3] NCCL INFO comm 0x1513200090d0 rank 3 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 00 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59567 [1] NCCL INFO comm 0x14703c0090d0 rank 1 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1217:59375:59571 [2] NCCL INFO comm 0x148ba40090d0 rank 2 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1227:164816:164929 [3] NCCL INFO comm 0x14e7280090d0 rank 11 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1227:164813:164924 [0] NCCL INFO comm 0x14c0ec0090d0 rank 8 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1227:164814:164925 [1] NCCL INFO comm 0x14cb800090d0 rank 9 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1227:164815:164931 [2] NCCL INFO comm 0x1519200090d0 rank 10 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 01 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 02 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Channel 03 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1222:121252:121366 [3] NCCL INFO comm 0x1465080090d0 rank 7 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1222:121250:121368 [1] NCCL INFO comm 0x14f6d80090d0 rank 5 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1222:121249:121364 [0] NCCL INFO comm 0x146cf40090d0 rank 4 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1222:121251:121362 [2] NCCL INFO comm 0x1479880090d0 rank 6 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default0]:barrier after loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default3]:barrier after loading kernels
[default1]:barrier after loading kernels
[default0]:barrier after loading kernels
[default2]:barrier after loading kernels
[default1]:barrier after loading kernels
[default2]:barrier after loading kernels
[default3]:barrier after loading kernels
[default0]:barrier after loading kernels
[default3]:barrier after loading kernels
[default1]:barrier after loading kernels
[default2]:barrier after loading kernels
[default2]:barrier after loading kernels
[default0]:barrier after loading kernels
[default3]:barrier after loading kernels
[default1]:barrier after loading kernels
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 16.642 seconds
[default0]:time to initialize megatron (seconds): 72.890
[default0]:[after megatron is initialized] datetime: 2023-04-23 11:32:56 
[default0]:building GPT model ...
[default0]:[2023-04-23 11:32:57,023] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-04-23 11:32:57,024] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-23 11:32:57,024] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.95 GB, percent = 3.2%
[default0]:SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
[default0]:Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=1, model=0): 2, ProcessCoord(pipe=0, data=1, model=1): 3, ProcessCoord(pipe=0, data=2, model=0): 4, ProcessCoord(pipe=0, data=2, model=1): 5, ProcessCoord(pipe=0, data=3, model=0): 6, ProcessCoord(pipe=0, data=3, model=1): 7, ProcessCoord(pipe=0, data=4, model=0): 8, ProcessCoord(pipe=0, data=4, model=1): 9, ProcessCoord(pipe=0, data=5, model=0): 10, ProcessCoord(pipe=0, data=5, model=1): 11, ProcessCoord(pipe=0, data=6, model=0): 12, ProcessCoord(pipe=0, data=6, model=1): 13, ProcessCoord(pipe=0, data=7, model=0): 14, ProcessCoord(pipe=0, data=7, model=1): 15}
[default0]:[2023-04-23 11:32:57,403] [INFO] [module.py:358:_partition_layers] Partitioning pipeline stages with method type:transformer
[default0]:stage=0 layers=31
[default0]:     0: _to_float16
[default0]:     1: EmbeddingPipe
[default0]:     2: <lambda>
[default0]:     3: ParallelTransformerLayerPipe
[default0]:     4: ParallelTransformerLayerPipe
[default0]:     5: ParallelTransformerLayerPipe
[default0]:     6: ParallelTransformerLayerPipe
[default0]:     7: ParallelTransformerLayerPipe
[default0]:     8: ParallelTransformerLayerPipe
[default0]:     9: ParallelTransformerLayerPipe
[default0]:    10: ParallelTransformerLayerPipe
[default0]:    11: ParallelTransformerLayerPipe
[default0]:    12: ParallelTransformerLayerPipe
[default0]:    13: ParallelTransformerLayerPipe
[default0]:    14: ParallelTransformerLayerPipe
[default0]:    15: ParallelTransformerLayerPipe
[default0]:    16: ParallelTransformerLayerPipe
[default0]:    17: ParallelTransformerLayerPipe
[default0]:    18: ParallelTransformerLayerPipe
[default0]:    19: ParallelTransformerLayerPipe
[default0]:    20: ParallelTransformerLayerPipe
[default0]:    21: ParallelTransformerLayerPipe
[default0]:    22: ParallelTransformerLayerPipe
[default0]:    23: ParallelTransformerLayerPipe
[default0]:    24: ParallelTransformerLayerPipe
[default0]:    25: ParallelTransformerLayerPipe
[default0]:    26: ParallelTransformerLayerPipe
[default0]:    27: undo
[default0]:    28: MixedFusedLayerNorm
[default0]:    29: EmbeddingPipe
[default0]:    30: float16_to_fp32
[default0]:  loss: CrossEntropy
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:[2023-04-23 11:32:57,648] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-04-23 11:32:57,649] [INFO] [utils.py:786:see_memory_usage] MA 0.34 GB         Max_MA 0.34 GB         CA 0.37 GB         Max_CA 0 GB 
[default0]:[2023-04-23 11:32:57,649] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.99 GB, percent = 3.2%
[default0]:setting training iterations to 976
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-04-23 11:32:57,651] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Trees [0] 2/-1/-1->5->4 [1] -1/-1/-1->5->4
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 00/0 : 5[c4000] -> 6[44000] [receive] via NET/IB/1
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Trees [0] 3/-1/-1->2->5 [1] 3/0/-1->2->6
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Trees [0] 2/-1/-1->5->4 [1] -1/-1/-1->5->4
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Channel 00/0 : 5[c4000] -> 6[44000] [send] via NET/IB/1
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 00/0 : 7[c4000] -> 0[44000] [receive] via NET/IB/1
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 01/0 : 5[c4000] -> 6[44000] [receive] via NET/IB/1
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 00 : 6[44000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 00/0 : 1[c4000] -> 2[44000] [receive] via NET/IB/1
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Channel 00/0 : 7[c4000] -> 0[44000] [send] via NET/IB/1
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Trees [0] 3/-1/-1->2->5 [1] 3/0/-1->2->6
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Channel 01/0 : 5[c4000] -> 6[44000] [send] via NET/IB/1
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 01/0 : 7[c4000] -> 0[44000] [receive] via NET/IB/1
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 00 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 01 : 6[44000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 00 : 6[3000] -> 7[84000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Channel 01/0 : 7[c4000] -> 0[44000] [send] via NET/IB/1
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Channel 00/0 : 1[c4000] -> 2[44000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 00/0 : 3[c4000] -> 4[44000] [receive] via NET/IB/1
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 01/0 : 1[c4000] -> 2[44000] [receive] via NET/IB/1
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 00 : 2[44000] -> 3[c4000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Channel 01/0 : 1[c4000] -> 2[44000] [send] via NET/IB/1
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 01 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 01 : 2[44000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 00 : 0[3000] -> 1[84000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 01/0 : 3[c4000] -> 4[44000] [receive] via NET/IB/1
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 00 : 4[44000] -> 5[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Channel 00/0 : 3[c4000] -> 4[44000] [send] via NET/IB/1
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Channel 01/0 : 3[c4000] -> 4[44000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 00 : 2[3000] -> 3[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 01 : 6[3000] -> 7[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 01 : 4[44000] -> 5[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 01 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 00 : 4[3000] -> 5[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 01 : 2[3000] -> 3[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Connected all rings
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Channel 00 : 7[c4000] -> 6[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 01 : 4[3000] -> 5[84000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Connected all rings
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 01/0 : 0[44000] -> 2[44000] [send] via NET/IB/1
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Channel 01/0 : 4[44000] -> 3[c4000] [receive] via NET/IB/1
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Channel 00 : 3[c4000] -> 2[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Channel 01 : 7[c4000] -> 6[44000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Channel 00 : 7[84000] -> 6[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Channel 00/0 : 2[44000] -> 5[c4000] [receive] via NET/IB/1
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Channel 00 : 1[84000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Connected all rings
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 00/0 : 4[44000] -> 6[44000] [receive] via NET/IB/1
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Channel 01 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Channel 01 : 7[84000] -> 6[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Channel 01 : 3[c4000] -> 2[44000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 01/0 : 0[44000] -> 2[44000] [receive] via NET/IB/1
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 00/0 : 4[44000] -> 6[44000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Connected all rings
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [receive] via NET/IB/0
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 00/0 : 4[44000] -> 0[44000] [receive] via NET/IB/1
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Connected all rings
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 00/0 : 2[44000] -> 5[c4000] [send] via NET/IB/1
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 01/0 : 2[44000] -> 6[44000] [receive] via NET/IB/1
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 00/0 : 0[44000] -> 4[44000] [send] via NET/IB/1
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [receive] via NET/IB/0
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Channel 00 : 3[84000] -> 2[3000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Channel 01 : 3[84000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 00/0 : 0[44000] -> 4[44000] [receive] via NET/IB/1
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [send] via NET/IB/0
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Channel 00/0 : 5[c4000] -> 2[44000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 01/0 : 6[44000] -> 2[44000] [send] via NET/IB/1
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 00/0 : 4[44000] -> 0[44000] [send] via NET/IB/1
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 01/0 : 6[44000] -> 2[44000] [receive] via NET/IB/1
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 01/0 : 2[44000] -> 6[44000] [send] via NET/IB/1
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [send] via NET/IB/0
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 00/0 : 6[44000] -> 4[44000] [receive] via NET/IB/1
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Channel 01/0 : 2[44000] -> 0[44000] [receive] via NET/IB/1
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 00/0 : 5[c4000] -> 2[44000] [receive] via NET/IB/1
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Channel 00/0 : 6[44000] -> 4[44000] [send] via NET/IB/1
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [receive] via NET/IB/0
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Channel 00 : 5[c4000] -> 4[44000] via P2P/IPC/read
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Channel 01 : 5[c4000] -> 4[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [receive] via NET/IB/0
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Channel 00 : 5[84000] -> 4[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181677 [3] NCCL INFO comm 0x1486bc0090d0 rank 7 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1232:181494:181676 [1] NCCL INFO comm 0x14f0e00090d0 rank 6 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Channel 01/0 : 2[44000] -> 0[44000] [send] via NET/IB/1
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Channel 01 : 5[84000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Channel 01/0 : 4[44000] -> 3[c4000] [send] via NET/IB/1
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1232:181493:181678 [0] NCCL INFO comm 0x14eaf80090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1232:181495:181679 [2] NCCL INFO comm 0x14a4880090d0 rank 7 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [send] via NET/IB/0
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1217:59376:59633 [3] NCCL INFO comm 0x1512d80090d0 rank 1 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1227:164814:164984 [1] NCCL INFO comm 0x14cb340090d0 rank 4 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1227:164816:164983 [3] NCCL INFO comm 0x14e6e00090d0 rank 5 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1217:59374:59632 [1] NCCL INFO comm 0x146ff40090d0 rank 0 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1227:164815:164986 [2] NCCL INFO comm 0x1518e40090d0 rank 5 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1227:164813:164985 [0] NCCL INFO comm 0x14c0a00090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:59374:59374 [1] NCCL INFO Launch mode Parallel
[default1]:n2gpu1222:121250:121420 [1] NCCL INFO comm 0x14f6880090d0 rank 2 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1222:121252:121421 [3] NCCL INFO comm 0x1464c00090d0 rank 3 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1222:121251:121422 [2] NCCL INFO comm 0x14793c0090d0 rank 3 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1217:59375:59635 [2] NCCL INFO comm 0x148b580090d0 rank 1 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1222:121249:121423 [0] NCCL INFO comm 0x146ca80090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59636 [0] NCCL INFO comm 0x148ba80090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Launch mode Parallel
[default0]:[2023-04-23 11:33:16,051] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-04-23 11:33:16,056] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-04-23 11:33:16,057] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:[2023-04-23 11:33:16,065] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-04-23 11:33:16,066] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-04-23 11:33:16,066] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[default0]:[2023-04-23 11:33:16,066] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[default0]:[2023-04-23 11:33:16,066] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[default0]:[2023-04-23 11:33:16,066] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-04-23 11:33:16,066] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.23025107383728027 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.376206636428833 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.3116304874420166 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.10300660133361816 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default3]:Loading extension module utils...
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default2]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.2699615955352783 seconds
[default3]:Time to load utils op: 0.3815178871154785 seconds
[default1]:Time to load utils op: 0.3710205554962158 seconds
[default2]:Time to load utils op: 0.27954888343811035 seconds
[default0]:Rank: 0 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default3]:Rank: 3 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default1]:Rank: 1 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default2]:Rank: 2 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default0]:Rank: 4 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default2]:Rank: 6 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default1]:Rank: 5 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default3]:Rank: 7 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.0379672050476074 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.0278635025024414 seconds
[default2]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.0344173908233643 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.1371285915374756 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.158212900161743 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.148150682449341 seconds
[default2]:Time to load utils op: 3.045397996902466 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.126408576965332 seconds
[default2]:Rank: 10 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default0]:Rank: 8 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default3]:Rank: 11 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default0]:Rank: 12 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default3]:Rank: 15 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default1]:Rank: 9 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default2]:Rank: 14 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default1]:Rank: 13 partition count [8, 8, 8] and sizes[(12533760, False), (9699328, False), (29440, False)] 
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.00597834587097168 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.021536588668823242 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.004328727722167969 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.002480745315551758 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.006098508834838867 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.005458831787109375 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.012682676315307617 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.010012149810791016 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.008988380432128906 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.023725271224975586 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.017197608947753906 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.015383005142211914 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.016405582427978516 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.015133380889892578 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.011151790618896484 seconds
[default0]:[2023-04-23 11:33:20,957] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-04-23 11:33:20,957] [INFO] [utils.py:786:see_memory_usage] MA 0.42 GB         Max_MA 0.42 GB         CA 0.42 GB         Max_CA 0 GB 
[default0]:[2023-04-23 11:33:20,958] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.61 GB, percent = 3.3%
[default0]:[2023-04-23 11:33:21,087] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-04-23 11:33:21,087] [INFO] [utils.py:786:see_memory_usage] MA 0.58 GB         Max_MA 0.67 GB         CA 0.67 GB         Max_CA 1 GB 
[default0]:[2023-04-23 11:33:21,087] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.61 GB, percent = 3.3%
[default0]:[2023-04-23 11:33:21,087] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[default0]:[2023-04-23 11:33:21,209] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-04-23 11:33:21,209] [INFO] [utils.py:786:see_memory_usage] MA 0.58 GB         Max_MA 0.58 GB         CA 0.67 GB         Max_CA 1 GB 
[default0]:[2023-04-23 11:33:21,210] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.61 GB, percent = 3.3%
[default0]:[2023-04-23 11:33:21,211] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-04-23 11:33:21,211] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-04-23 11:33:21,211] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x148c81640c70>
[default0]:[2023-04-23 11:33:21,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-04-23 11:33:21,211] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   amp_enabled .................. False
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   amp_params ................... False
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x148c80f72050>
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   communication_data_type ...... None
[default0]:[2023-04-23 11:33:21,212] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   disable_allgather ............ False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   dump_state ................... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[default0]:[2023-04-23 11:33:21,213] [INFO] [config.py:957:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   fp16_enabled ................. True
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   global_rank .................. 0
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 64
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[default0]:[2023-04-23 11:33:21,214] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 4096
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   loss_scale ................... 0
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   memory_breakdown ............. False
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   optimizer_name ............... None
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   optimizer_params ............. None
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   pld_enabled .................. False
[default0]:[2023-04-23 11:33:21,315] [INFO] [config.py:957:print]   pld_params ................... False
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   prescale_gradients ........... False
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   scheduler_name ............... None
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   scheduler_params ............. None
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   sparse_attention ............. None
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   steps_per_print .............. 2000
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   train_batch_size ............. 512
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   world_size ................... 8
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   zero_enabled ................. True
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:957:print]   zero_optimization_stage ...... 1
[default0]:[2023-04-23 11:33:21,316] [INFO] [config.py:943:print_user_config]   json = {
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "train_batch_size": 512, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 1
[default0]:    }, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 12
[default0]:    }, 
[default0]:    "steps_per_print": 2.000000e+03, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0009691715240478516 seconds
[default0]:[2023-04-23 11:33:21,318] [INFO] [engine.py:81:__init__] CONFIG: micro_batches=64 micro_batch_size=1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59658 [3] NCCL INFO comm 0x1512a80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1217:59375:59657 [2] NCCL INFO comm 0x148b2c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59375 [2] NCCL INFO Launch mode Parallel
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165002 [0] NCCL INFO comm 0x14c0640090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1227:164813:164813 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1227:164814:165003 [1] NCCL INFO comm 0x14caf80090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1227:164815:164999 [2] NCCL INFO comm 0x1518ac0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1227:164815:164815 [2] NCCL INFO Launch mode Parallel
[default3]:n2gpu1227:164816:165000 [3] NCCL INFO comm 0x14e6d80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Connected all rings
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1222:121251:121444 [2] NCCL INFO comm 0x1479100090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1222:121252:121446 [3] NCCL INFO comm 0x1464b80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Connected all rings
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1222:121249:121442 [0] NCCL INFO comm 0x146c6c0090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1222:121251:121251 [2] NCCL INFO Launch mode Parallel
[default1]:n2gpu1222:121250:121445 [1] NCCL INFO comm 0x14f6540090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Connected all rings
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1222:121249:121249 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1217:59374:59663 [1] NCCL INFO comm 0x146fc40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1232:181496:181695 [3] NCCL INFO comm 0x1486940090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1232:181495:181692 [2] NCCL INFO comm 0x14a4580090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1232:181495:181495 [2] NCCL INFO Launch mode Parallel
[default0]:n2gpu1232:181493:181694 [0] NCCL INFO comm 0x14eac00090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1232:181493:181493 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1232:181494:181696 [1] NCCL INFO comm 0x14f0a40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1217:59373:59662 [0] NCCL INFO comm 0x148b780090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Launch mode Parallel
[default0]:[2023-04-23 11:33:24,909] [INFO] [engine.py:136:__init__] RANK=0 STAGE=0 LAYERS=31 [0, 31) STAGE_PARAMS=178100224 (178.100M) TOTAL_PARAMS=356200448 (356.200M) UNIQUE_PARAMS=356200448 (356.200M)
[default2]:[2023-04-23 11:33:24,957] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-23 11:33:24,947] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-23 11:33:24,968] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-23 11:33:24,946] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-23 11:33:24,985] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-23 11:33:24,974] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-23 11:33:24,956] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-23 11:33:24,947] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-23 11:33:24,968] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file checkpoints/gpt2-dist-1 
[default0]:    will not load any checkpoints and will start from random
[default3]:[2023-04-23 11:33:24,979] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-23 11:33:24,957] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-23 11:33:24,977] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:time (ms) | load-checkpoint: 49.97
[default2]:[2023-04-23 11:33:24,981] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-23 11:33:24,957] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-23 11:33:24,968] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-23 11:33:24,946] [INFO] [engine.py:136:__init__] RANK=1 STAGE=0 LAYERS=31 [0, 31) STAGE_PARAMS=178100224 (178.100M) TOTAL_PARAMS=356200448 (356.200M) UNIQUE_PARAMS=356200448 (356.200M)
[default1]:[2023-04-23 11:33:24,946] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist-1/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:estimated model parameters: 0.356200448
[default0]:estimated model parameters without embeddings: 0.302460928
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-04-23 11:33:25 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      500000
[default0]:    validation: 102400
[default0]:    test:       5120
[default0]:> building train, validation, and test datasets for GPT ...
[default0]: > building dataset index ...
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/utils.py:349: UserWarning: Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings
[default0]:  warnings.warn("Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings")
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.035097 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9690) total of 9690 documents
[default0]:    validation:
[default0]:     document indices in [9690, 9990) total of 300 documents
[default0]:    test:
[default0]:     document indices in [9990, 10000) total of 10 documents
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (21154) is smaller than 95.0% of number of samples per epoch (28167), setting separate_last_epoch to True
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.006376
[default0]:    using:
[default0]:     number of documents:       9690
[default0]:     number of epochs:          18
[default0]:     sequence length:           1024
[default0]:     total number of samples:   507013
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.047415
[default0]: > building shuffle index with split [0, 478846) and [478846, 507013) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.011033
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Trees [0] 2/-1/-1->5->4 [1] -1/-1/-1->5->4
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Trees [0] 3/-1/-1->2->5 [1] 3/0/-1->2->6
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 00 : 0[3000] -> 1[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 00 : 6[3000] -> 7[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 01 : 6[3000] -> 7[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 01 : 0[3000] -> 1[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 00 : 2[3000] -> 3[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 00 : 4[3000] -> 5[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 01 : 2[3000] -> 3[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 01 : 4[3000] -> 5[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Channel 00 : 7[84000] -> 6[3000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Channel 01 : 7[84000] -> 6[3000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Channel 00 : 1[84000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Channel 01 : 1[84000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [receive] via NET/IB/0
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Channel 00 : 3[84000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [send] via NET/IB/0
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Channel 01 : 3[84000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [send] via NET/IB/0
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [receive] via NET/IB/0
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Channel 00 : 5[84000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [send] via NET/IB/0
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Channel 01 : 5[84000] -> 4[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1232:181495:181706 [2] NCCL INFO comm 0x14a44c0090d0 rank 7 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1232:181493:181705 [0] NCCL INFO comm 0x14eaac0090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1227:164813:165013 [0] NCCL INFO comm 0x14c0580090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1227:164815:165012 [2] NCCL INFO comm 0x15189c0090d0 rank 5 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:59373:59671 [0] NCCL INFO comm 0x148b6c0090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1217:59375:59672 [2] NCCL INFO comm 0x148b180090d0 rank 1 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1222:121251:121456 [2] NCCL INFO comm 0x1478fc0090d0 rank 3 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1222:121249:121455 [0] NCCL INFO comm 0x146c5c0090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Connected all rings
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:59373:59681 [0] NCCL INFO comm 0x148b540090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_500000ns_1024sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_500000ns_1024sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_500000ns_1024sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.022 seconds
[default0]:    total number of samples: 507014
[default0]:    total number of epochs: 18
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (838) is smaller than 95.0% of number of samples per epoch (914), setting separate_last_epoch to True
[default2]:n2gpu1217:59375:59679 [2] NCCL INFO comm 0x148b080090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1222:121251:121463 [2] NCCL INFO comm 0x1478ec0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1227:164813:165022 [0] NCCL INFO comm 0x14c03c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1227:164815:165020 [2] NCCL INFO comm 0x1518840090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1232:181495:181715 [2] NCCL INFO comm 0x14a43c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1232:181493:181713 [0] NCCL INFO comm 0x14ea940090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1222:121249:121465 [0] NCCL INFO comm 0x146c400090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.034865
[default0]:    using:
[default0]:     number of documents:       300
[default0]:     number of epochs:          112
[default0]:     sequence length:           1024
[default0]:     total number of samples:   102477
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.033920
[default0]: > building shuffle index with split [0, 101562) and [101562, 102477) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.059894
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_102400ns_1024sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_102400ns_1024sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_102400ns_1024sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.002 seconds
[default0]:    total number of samples: 102478
[default0]:    total number of epochs: 112
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (4) is smaller than 95.0% of number of samples per epoch (31), setting separate_last_epoch to True
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.043066
[default0]:    using:
[default0]:     number of documents:       10
[default0]:     number of epochs:          162
[default0]:     sequence length:           1024
[default0]:     total number of samples:   5148
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.055906
[default0]: > building shuffle index with split [0, 5116) and [5116, 5148) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.047914
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_5120ns_1024sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_5120ns_1024sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_5120ns_1024sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.002 seconds
[default0]:    total number of samples: 5149
[default0]:    total number of epochs: 162
[default0]:> finished creating GPT datasets ...
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Connected all rings
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Connected all rings
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1222:121249:121474 [0] NCCL INFO comm 0x146c340090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1222:121250:121476 [1] NCCL INFO comm 0x14f6480090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1217:59375:59690 [2] NCCL INFO comm 0x148b000090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1217:59375:59375 [2] NCCL INFO Launch mode Parallel
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:59376:59691 [3] NCCL INFO comm 0x15129c0090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:121249:121249 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Connected all rings
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1227:164814:165032 [1] NCCL INFO comm 0x14caec0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1222:121252:121475 [3] NCCL INFO comm 0x1464840090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1232:181493:181721 [0] NCCL INFO comm 0x14ea880090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1232:181494:181724 [1] NCCL INFO comm 0x14f0980090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1227:164813:165029 [0] NCCL INFO comm 0x14c0300090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1232:181496:181725 [3] NCCL INFO comm 0x1486840090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1232:181495:181723 [2] NCCL INFO comm 0x14a4340090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1232:181495:181495 [2] NCCL INFO Launch mode Parallel
[default3]:n2gpu1227:164816:165033 [3] NCCL INFO comm 0x14e6a40090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1232:181493:181493 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1227:164815:165031 [2] NCCL INFO comm 0x1518780090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1227:164815:164815 [2] NCCL INFO Launch mode Parallel
[default0]:n2gpu1227:164813:164813 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1222:121251:121472 [2] NCCL INFO comm 0x1478e00090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1222:121251:121251 [2] NCCL INFO Launch mode Parallel
[default1]:n2gpu1217:59374:59688 [1] NCCL INFO comm 0x146fb80090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1217:59373:59687 [0] NCCL INFO comm 0x148b480090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:59373:59373 [0] NCCL INFO Launch mode Parallel
[default1]:[001-000] 0.3562B / 0.3025B
[default3]:time (ms) | model-and-optimizer-setup: 28047.89 | train/valid/test-data-iterators-setup: 7809.62
[default0]:[after dataloaders are built] datetime: 2023-04-23 11:33:45 
[default0]:done with setup ...
[default0]:training ...
[default0]:Number of parameters: [tensor rank - pipeline rank] w/ and w/o embeddings:
[default0]:[000-000] 0.3562B / 0.3025B
[default0]:[before the start of training step] datetime: 2023-04-23 11:33:45 
[default0]:[2023-04-23 11:33:45,488] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[default0]:[2023-04-23 11:33:45,488] [INFO] [checkpointing.py:530:forward] ----Partition Activations True, CPU CHECKPOINTING False
[default0]:[2023-04-23 11:33:45,488] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 24 total layers
[default0]:[2023-04-23 11:33:45,488] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[default0]:[2023-04-23 11:33:45,488] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1217:59374:60588 [1] NCCL INFO comm 0x146f200090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1217:59376:60589 [3] NCCL INFO comm 0x1512000090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Connected all rings
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:181493:182627 [0] NCCL INFO comm 0x14e9d00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1227:164815:165930 [2] NCCL INFO comm 0x1517b40090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1227:164816:165928 [3] NCCL INFO comm 0x14e6040090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Connected all rings
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1227:164814:165931 [1] NCCL INFO comm 0x14ca500090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1232:181496:182628 [3] NCCL INFO comm 0x1485ec0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1217:59375:60593 [2] NCCL INFO comm 0x148a3c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1227:164813:165933 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:164813:165933 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:164813:165933 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:164813:165933 [0] NCCL INFO comm 0x14bf7c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1232:181495:182625 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:181495:182625 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:181495:182625 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1232:181495:182625 [2] NCCL INFO comm 0x14a3740090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1222:121251:122371 [2] NCCL INFO comm 0x14781c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1222:121252:122374 [3] NCCL INFO comm 0x1463e40090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:121249:122373 [0] NCCL INFO comm 0x146b800090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1222:121250:122375 [1] NCCL INFO comm 0x14f5b40090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Connected all rings
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1232:181494:182632 [1] NCCL INFO comm 0x14effc0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1217:59373:60591 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:59373:60591 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:59373:60591 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:59373:60591 [0] NCCL INFO comm 0x148a840090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:[Rank 0] (after 2 iterations) memory (MB) | allocated: 797.87646484375 | max allocated: 1496.32568359375 | reserved: 1854.0 | max reserved: 1854.0
[default1]:[Rank 1] (after 2 iterations) memory (MB) | allocated: 797.87646484375 | max allocated: 1496.32568359375 | reserved: 1854.0 | max reserved: 1854.0
[default3]: iteration        2/     976 | consumed samples:         1024 | consumed tokens:      1048576 | elapsed time per iteration (s): 313.92 | learning rate: 1.000E-04 | global batch size:   512 | lm loss: 1.048735E+01 | loss scale: 4096.0 | grad norm: 6.960 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.631 | TFLOPs: 0.33 |
[default3]: iteration        4/     976 | consumed samples:         2048 | consumed tokens:      2097152 | elapsed time per iteration (s): 307.00 | learning rate: 1.000E-04 | global batch size:   512 | lm loss: 9.578474E+00 | loss scale: 4096.0 | grad norm: 2.321 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.668 | TFLOPs: 0.33 |
[default3]: iteration        6/     976 | consumed samples:         3072 | consumed tokens:      3145728 | elapsed time per iteration (s): 306.57 | learning rate: 9.999E-05 | global batch size:   512 | lm loss: 9.339188E+00 | loss scale: 4096.0 | grad norm: 1.998 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 0.33 |
[default3]: iteration        8/     976 | consumed samples:         4096 | consumed tokens:      4194304 | elapsed time per iteration (s): 305.75 | learning rate: 9.998E-05 | global batch size:   512 | lm loss: 9.096852E+00 | loss scale: 4096.0 | grad norm: 1.671 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.675 | TFLOPs: 0.34 |
[default3]: iteration       10/     976 | consumed samples:         5120 | consumed tokens:      5242880 | elapsed time per iteration (s): 307.84 | learning rate: 9.997E-05 | global batch size:   512 | lm loss: 8.915846E+00 | loss scale: 4096.0 | grad norm: 1.294 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.663 | TFLOPs: 0.33 |
[default3]: iteration       12/     976 | consumed samples:         6144 | consumed tokens:      6291456 | elapsed time per iteration (s): 311.67 | learning rate: 9.996E-05 | global batch size:   512 | lm loss: 8.733294E+00 | loss scale: 4096.0 | grad norm: 1.473 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.643 | TFLOPs: 0.33 |
[default3]: iteration       14/     976 | consumed samples:         7168 | consumed tokens:      7340032 | elapsed time per iteration (s): 312.49 | learning rate: 9.995E-05 | global batch size:   512 | lm loss: 8.572758E+00 | loss scale: 4096.0 | grad norm: 1.422 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.638 | TFLOPs: 0.33 |
[default3]: iteration       16/     976 | consumed samples:         8192 | consumed tokens:      8388608 | elapsed time per iteration (s): 311.03 | learning rate: 9.993E-05 | global batch size:   512 | lm loss: 8.397243E+00 | loss scale: 4096.0 | grad norm: 1.125 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.646 | TFLOPs: 0.33 |
[default3]: iteration       18/     976 | consumed samples:         9216 | consumed tokens:      9437184 | elapsed time per iteration (s): 305.98 | learning rate: 9.992E-05 | global batch size:   512 | lm loss: 8.268126E+00 | loss scale: 4096.0 | grad norm: 0.954 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.673 | TFLOPs: 0.34 |
[default3]: iteration       20/     976 | consumed samples:        10240 | consumed tokens:     10485760 | elapsed time per iteration (s): 307.13 | learning rate: 9.990E-05 | global batch size:   512 | lm loss: 8.138083E+00 | loss scale: 4096.0 | grad norm: 0.906 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.667 | TFLOPs: 0.33 |
[default3]: iteration       22/     976 | consumed samples:        11264 | consumed tokens:     11534336 | elapsed time per iteration (s): 306.75 | learning rate: 9.988E-05 | global batch size:   512 | lm loss: 7.998189E+00 | loss scale: 4096.0 | grad norm: 0.888 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.669 | TFLOPs: 0.33 |
[default3]: iteration       24/     976 | consumed samples:        12288 | consumed tokens:     12582912 | elapsed time per iteration (s): 313.18 | learning rate: 9.985E-05 | global batch size:   512 | lm loss: 7.899903E+00 | loss scale: 4096.0 | grad norm: 0.810 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.635 | TFLOPs: 0.33 |
[default3]: iteration       26/     976 | consumed samples:        13312 | consumed tokens:     13631488 | elapsed time per iteration (s): 307.84 | learning rate: 9.983E-05 | global batch size:   512 | lm loss: 7.816724E+00 | loss scale: 4096.0 | grad norm: 0.582 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.663 | TFLOPs: 0.33 |
[default3]: iteration       28/     976 | consumed samples:        14336 | consumed tokens:     14680064 | elapsed time per iteration (s): 304.84 | learning rate: 9.980E-05 | global batch size:   512 | lm loss: 7.752411E+00 | loss scale: 4096.0 | grad norm: 1.109 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.680 | TFLOPs: 0.34 |
[default3]: iteration       30/     976 | consumed samples:        15360 | consumed tokens:     15728640 | elapsed time per iteration (s): 304.19 | learning rate: 9.977E-05 | global batch size:   512 | lm loss: 7.662124E+00 | loss scale: 4096.0 | grad norm: 0.601 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.683 | TFLOPs: 0.34 |
[default3]: iteration       32/     976 | consumed samples:        16384 | consumed tokens:     16777216 | elapsed time per iteration (s): 306.65 | learning rate: 9.974E-05 | global batch size:   512 | lm loss: 7.607176E+00 | loss scale: 4096.0 | grad norm: 0.459 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 0.33 |
[default3]: iteration       34/     976 | consumed samples:        17408 | consumed tokens:     17825792 | elapsed time per iteration (s): 305.24 | learning rate: 9.970E-05 | global batch size:   512 | lm loss: 7.565333E+00 | loss scale: 4096.0 | grad norm: 0.681 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.677 | TFLOPs: 0.34 |
[default3]: iteration       36/     976 | consumed samples:        18432 | consumed tokens:     18874368 | elapsed time per iteration (s): 308.10 | learning rate: 9.967E-05 | global batch size:   512 | lm loss: 7.554423E+00 | loss scale: 4096.0 | grad norm: 0.501 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.662 | TFLOPs: 0.33 |
[default3]: iteration       38/     976 | consumed samples:        19456 | consumed tokens:     19922944 | elapsed time per iteration (s): 308.13 | learning rate: 9.963E-05 | global batch size:   512 | lm loss: 7.523996E+00 | loss scale: 4096.0 | grad norm: 0.450 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.662 | TFLOPs: 0.33 |
[default3]: iteration       40/     976 | consumed samples:        20480 | consumed tokens:     20971520 | elapsed time per iteration (s): 307.81 | learning rate: 9.959E-05 | global batch size:   512 | lm loss: 7.497727E+00 | loss scale: 4096.0 | grad norm: 0.419 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.663 | TFLOPs: 0.33 |
[default3]: iteration       42/     976 | consumed samples:        21504 | consumed tokens:     22020096 | elapsed time per iteration (s): 309.66 | learning rate: 9.955E-05 | global batch size:   512 | lm loss: 7.462561E+00 | loss scale: 4096.0 | grad norm: 0.390 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.653 | TFLOPs: 0.33 |
[default3]: iteration       44/     976 | consumed samples:        22528 | consumed tokens:     23068672 | elapsed time per iteration (s): 308.45 | learning rate: 9.950E-05 | global batch size:   512 | lm loss: 7.414631E+00 | loss scale: 4096.0 | grad norm: 0.379 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.660 | TFLOPs: 0.33 |
[default3]: iteration       46/     976 | consumed samples:        23552 | consumed tokens:     24117248 | elapsed time per iteration (s): 308.58 | learning rate: 9.946E-05 | global batch size:   512 | lm loss: 7.406574E+00 | loss scale: 4096.0 | grad norm: 0.354 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 0.33 |
[default3]: iteration       48/     976 | consumed samples:        24576 | consumed tokens:     25165824 | elapsed time per iteration (s): 310.17 | learning rate: 9.941E-05 | global batch size:   512 | lm loss: 7.381006E+00 | loss scale: 4096.0 | grad norm: 0.822 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.651 | TFLOPs: 0.33 |
[default3]: iteration       50/     976 | consumed samples:        25600 | consumed tokens:     26214400 | elapsed time per iteration (s): 310.68 | learning rate: 9.936E-05 | global batch size:   512 | lm loss: 7.375161E+00 | loss scale: 4096.0 | grad norm: 0.424 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.648 | TFLOPs: 0.33 |
[default0]:[2023-04-23 16:06:05,259] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!
[default0]:[2023-04-23 16:06:05,490] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_01-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:05,501] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_01-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:05,768] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_01-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:05,769] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_03-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:05,768] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_01-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:05,768] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_03-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:05,839] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_03-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:05,840] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_04-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:05,839] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_03-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:05,839] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_04-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:05,899] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_04-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:05,899] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_05-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:05,900] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_04-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:05,900] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_05-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:05,965] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_05-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:05,965] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_06-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:05,964] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_05-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:05,965] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_06-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,007] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_06-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,007] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_07-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,008] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_06-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,008] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_07-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,069] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_07-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,069] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_08-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,108] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_08-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,108] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_09-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,107] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_07-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,108] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_08-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,141] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_08-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,141] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_09-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,142] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_09-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,142] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_10-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,208] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_09-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,208] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_10-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,240] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_10-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,240] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_11-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,287] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_10-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,287] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_11-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,317] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_11-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_12-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,370] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_12-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,370] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_13-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,350] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_11-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,350] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_12-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,405] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_12-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,405] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_13-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,451] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_13-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,451] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_14-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,512] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_14-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,512] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_15-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,550] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_13-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,551] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_14-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,619] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_14-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,619] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_15-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,551] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_15-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,552] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_16-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,628] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_16-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,628] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_17-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_15-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,727] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_16-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,762] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_16-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,762] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_17-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,823] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_17-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,824] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_18-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,824] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_17-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,824] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_18-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,874] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_18-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,874] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_19-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,875] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_18-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,875] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_19-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:06,934] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_19-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,934] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_20-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:06,999] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_20-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:06,999] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_21-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:06,933] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_19-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,933] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_20-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:06,998] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_20-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:06,998] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_21-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:07,063] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_21-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,064] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_22-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:07,138] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_22-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,139] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_23-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:07,064] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_21-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,064] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_22-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:07,139] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_22-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,139] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_23-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:07,210] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_23-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,210] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_24-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:07,204] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_23-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,204] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_24-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:07,231] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_24-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,231] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_25-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:07,249] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_24-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_25-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:07,311] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_25-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,311] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_26-model_00-model_states.pt...
[default1]:[2023-04-23 16:06:07,291] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_25-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,291] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_26-model_01-model_states.pt...
[default1]:[2023-04-23 16:06:07,345] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_26-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,345] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_28-model_01-model_states.pt...
[default0]:[2023-04-23 16:06:07,373] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_26-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,373] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/layer_28-model_00-model_states.pt...
[default0]:[2023-04-23 16:06:07,431] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_28-model_00-model_states.pt.
[default0]:[2023-04-23 16:06:07,432] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-dist-1/global_step50/mp_rank_00_model_states.pt
[default0]:[2023-04-23 16:06:07,432] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/mp_rank_00_model_states.pt...
[default1]:[2023-04-23 16:06:07,408] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/layer_28-model_01-model_states.pt.
[default1]:[2023-04-23 16:06:07,409] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: checkpoints/gpt2-dist-1/global_step50/mp_rank_01_model_states.pt
[default1]:[2023-04-23 16:06:07,409] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/mp_rank_01_model_states.pt...
[default1]:[2023-04-23 16:06:07,451] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/mp_rank_01_model_states.pt.
[default0]:[2023-04-23 16:06:07,472] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/mp_rank_00_model_states.pt.
[default1]:[2023-04-23 16:06:08,500] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_6_mp_rank_01_optim_states.pt...
[default0]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_6_mp_rank_00_optim_states.pt...
[default2]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_7_mp_rank_00_optim_states.pt...
[default1]:[2023-04-23 16:06:08,500] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt...
[default0]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default2]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_5_mp_rank_00_optim_states.pt...
[default3]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_5_mp_rank_01_optim_states.pt...
[default3]:[2023-04-23 16:06:08,500] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt...
[default0]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default0]:[2023-04-23 16:06:08,500] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_4_mp_rank_00_optim_states.pt...
[default2]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default1]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt...
[default2]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[default3]:[2023-04-23 16:06:08,499] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt...
[default0]:[2023-04-23 16:06:09,218] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_6_mp_rank_00_optim_states.pt.
[default0]:[2023-04-23 16:06:09,218] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_6_mp_rank_00_optim_states.pt
[default0]:[2023-04-23 16:06:09,218] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default2]:[2023-04-23 16:06:09,367] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default2]:[2023-04-23 16:06:09,367] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default2]:[2023-04-23 16:06:09,367] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-23 16:06:09,379] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_4_mp_rank_01_optim_states.pt.
[default1]:[2023-04-23 16:06:09,379] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_4_mp_rank_01_optim_states.pt
[default1]:[2023-04-23 16:06:09,379] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-23 16:06:09,702] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt.
[default1]:[2023-04-23 16:06:09,702] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt
[default1]:[2023-04-23 16:06:09,702] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default2]:[2023-04-23 16:06:09,702] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_7_mp_rank_00_optim_states.pt.
[default2]:[2023-04-23 16:06:09,702] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_7_mp_rank_00_optim_states.pt
[default2]:[2023-04-23 16:06:09,702] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-23 16:06:09,713] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-04-23 16:06:09,763] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-04-23 16:06:09,763] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default2]:[2023-04-23 16:06:09,694] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_5_mp_rank_00_optim_states.pt.
[default2]:[2023-04-23 16:06:09,694] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_5_mp_rank_00_optim_states.pt
[default2]:[2023-04-23 16:06:09,694] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default2]:[2023-04-23 16:06:09,803] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default2]:[2023-04-23 16:06:09,803] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default2]:[2023-04-23 16:06:09,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-23 16:06:10,031] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_4_mp_rank_00_optim_states.pt.
[default0]:[2023-04-23 16:06:10,031] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_4_mp_rank_00_optim_states.pt
[default0]:[2023-04-23 16:06:10,031] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-23 16:06:10,196] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-04-23 16:06:10,196] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-04-23 16:06:10,196] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default3]:[2023-04-23 16:06:10,409] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt.
[default3]:[2023-04-23 16:06:10,409] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt
[default3]:[2023-04-23 16:06:10,409] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-23 16:06:10,610] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt.
[default1]:[2023-04-23 16:06:10,611] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt
[default1]:[2023-04-23 16:06:10,611] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default1]:[2023-04-23 16:06:10,711] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_6_mp_rank_01_optim_states.pt.
[default1]:[2023-04-23 16:06:10,712] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_6_mp_rank_01_optim_states.pt
[default1]:[2023-04-23 16:06:10,712] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default3]:[2023-04-23 16:06:11,099] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt.
[default3]:[2023-04-23 16:06:11,100] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt
[default3]:[2023-04-23 16:06:11,100] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default3]:[2023-04-23 16:06:11,116] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_5_mp_rank_01_optim_states.pt.
[default3]:[2023-04-23 16:06:11,116] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_5_mp_rank_01_optim_states.pt
[default3]:[2023-04-23 16:06:11,116] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default3]:[2023-04-23 16:06:11,177] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_7_mp_rank_01_optim_states.pt.
[default3]:[2023-04-23 16:06:11,177] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist-1/global_step50/zero_pp_rank_7_mp_rank_01_optim_states.pt
[default3]:[2023-04-23 16:06:11,177] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:  successfully saved checkpoint at iteration      50 to checkpoints/gpt2-dist-1
[default3]:time (ms) | save-checkpoint: 6285.82
[default3]: iteration       52/     976 | consumed samples:        26624 | consumed tokens:     27262976 | elapsed time per iteration (s): 769.07 | learning rate: 9.931E-05 | global batch size:   512 | lm loss: 7.339378E+00 | loss scale: 4096.0 | grad norm: 1.140 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.666 | TFLOPs: 0.13 |
[default3]: iteration       54/     976 | consumed samples:        27648 | consumed tokens:     28311552 | elapsed time per iteration (s): 309.22 | learning rate: 9.925E-05 | global batch size:   512 | lm loss: 7.312183E+00 | loss scale: 4096.0 | grad norm: 0.997 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.656 | TFLOPs: 0.33 |
slurmstepd: error: *** JOB 3410151 ON n2gpu1217 CANCELLED AT 2023-04-23T16:32:31 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181493 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181494 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181495 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181496 closing signal SIGTERM
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121249 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121250 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121251 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121252 closing signal SIGTERM
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164813 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164814 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164815 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164816 closing signal SIGTERM
slurmstepd: error: *** STEP 3410151.0 ON n2gpu1217 CANCELLED AT 2023-04-23T16:32:31 DUE TO TIME LIMIT ***
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164813 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164814 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164815 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164816 closing signal SIGTERM
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59373 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59374 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59375 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59376 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121249 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121250 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121251 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 121252 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181493 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181494 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181495 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 181496 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59373 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59374 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59375 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 59376 closing signal SIGTERM
