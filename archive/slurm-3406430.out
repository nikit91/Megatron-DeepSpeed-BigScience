cpu-bind=MASK - n2gpu1217, task  0  0 [8534]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 4 --nnodes 4 --rdzv_id=1234 --rdzv_endpoint n2gpu1217:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 2 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 2 --hidden-size 8 --num-attention-heads 2 --seq-length 512 --max-position-embeddings 512 --micro-batch-size 1 --global-batch-size 256 --train-samples 10_000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --lr-warmup-samples 5 --min-lr 1e-6 --lr-decay-style cosine --lr-decay-samples 12 --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 1000 --log-interval 10 --save-interval 50 --eval-interval 50 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-dist --load checkpoints/gpt2-dist --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --zero-stage 1 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1218, task  1  0 [294511]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1231, task  2  0 [61240]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1217, task  0  0 [8648]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1232, task  3  0 [140149]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[default0]:pretrain_gpt.py main
[default2]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  abort_on_unmet_fused_kernel_constraints ......... False
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  bert_binary_head ................................ True
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  clip_grad ....................................... 1.0
[default0]:  codecarbon_dir .................................. None
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  curriculum_learning ............................. False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_size .............................. 8
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distributed_backend ............................. nccl
[default0]:  embed_layernorm ................................. False
[default0]:  embedding_path .................................. None
[default0]:  encoder_seq_length .............................. 512
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 50
[default0]:  eval_iters ...................................... 10
[default0]:  eval_only ....................................... None
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 1000
[default0]:  ffn_hidden_size ................................. 32
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  gigaflos_no_embeds .............................. 0
[default0]:  global_batch_size ............................... 256
[default0]:  glu_activation .................................. None
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 8
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_dim ......................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  kill_switch_path ................................ None
[default0]:  kv_channels ..................................... 4
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-dist
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 10
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_level ....................................... None
[default0]:  log_level_replica ............................... None
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_params_norm ................................. False
[default0]:  log_path ........................................ None
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  loss_on_targets_only ............................ False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ 12
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 5
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_prob ....................................... 0.15
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 512
[default0]:  mean_noise_span_length .......................... None
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mmap_warmup ..................................... False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  noise_density ................................... None
[default0]:  num_attention_heads ............................. 2
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_layers ...................................... 2
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  override_lr_scheduler ........................... False
[default0]:  pad_vocab_size_to ............................... None
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  position_embedding_type ......................... PositionEmbeddingType.absolute
[default0]:  pp_partition_method ............................. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  rank ............................................ 0
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  reweight_loss_based_on_position_frequency ....... False
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-dist
[default0]:  save_interval ................................... 50
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 512
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train_iteration_range ...................... None
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  sync_tp_duplicated_parameters ................... False
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 2
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  test_weighted_split_names ....................... None
[default0]:  test_weighted_split_paths ....................... None
[default0]:  test_weighted_split_paths_path .................. None
[default0]:  test_weighted_split_splits ...................... None
[default0]:  test_weighted_split_weights ..................... None
[default0]:  tile_factor ..................................... 1
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_name_or_path .......................... None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  train_iters ..................................... None
[default0]:  train_samples ................................... 10000
[default0]:  train_tokens .................................... None
[default0]:  train_weighted_split_paths ...................... None
[default0]:  train_weighted_split_paths_path ................. None
[default0]:  universal_checkpoint ............................ False
[default0]:  use_bnb_optimizer ............................... False
[default0]:  use_checkpoint_lr_scheduler ..................... False
[default0]:  use_contiguous_buffers_in_ddp ................... False
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  valid_num_workers ............................... 2
[default0]:  valid_weighted_split_names ...................... None
[default0]:  valid_weighted_split_paths ...................... None
[default0]:  valid_weighted_split_paths_path ................. None
[default0]:  valid_weighted_split_splits ..................... None
[default0]:  valid_weighted_split_weights .................... None
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  weight_decay .................................... 0.1
[default0]:  world_size ...................................... 16
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 1
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 32
[default0]:> building GPT2BPETokenizer tokenizer ...
[default2]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default2]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default1]:pretrain_gpt.py main
[default0]: > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
[default3]:WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=7482fcf git_branch=main ****
[default0]:> initializing torch distributed ...
[default0]:[2023-04-21 11:49:11,706] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default1]:pretrain_gpt.py main
[default2]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default3]:pretrain_gpt.py main
[default0]:> initializing tensor model parallel with size 2
[default0]:> initializing pipeline model parallel with size 1
[default2]:rank>0 waiting for rank 0 before loading kernels
[default0]:> setting random seeds to 42 ...
[default0]:[2023-04-21 12:01:43,502] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default2]:rank>0 waiting for rank 0 before loading kernels
[default3]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default3]:rank>0 waiting for rank 0 before loading kernels
[default1]:rank>0 waiting for rank 0 before loading kernels
[default1]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default2]:rank>0 waiting for rank 0 before loading kernels
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 1.675 seconds
[default0]:WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module fused_mix_prec_layer_norm_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module fused_mix_prec_layer_norm_cuda...
[default0]:rank 0 finished kernel load
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.99<0>
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.99<0>
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.99<0>
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.99<0>
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO Using network IB
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO Using network IB
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO Using network IB
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO Using network IB
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.99<0>
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO Using network IB
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO Using network IB
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.99<0>
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO Using network IB
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.99<0>
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO Using network IB
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO Using network IB
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.99<0>
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO Using network IB
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO Using network IB
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.86<0>
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.86<0>
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.86<0>
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.86<0>
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.86<0>
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO Using network IB
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.86<0>
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO Using network IB
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.86<0>
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO Using network IB
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.86<0>
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO Using network IB
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/8/-1->5->4 [3] 6/8/-1->5->4
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Trees [0] 9/12/-1->8->0 [1] 9/12/-1->8->0 [2] 9/-1/-1->8->5 [3] 9/-1/-1->8->5
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/4/-1->9->8 [2] 10/-1/-1->9->8 [3] 10/-1/-1->9->8
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/-1/-1->13->12 [3] 14/-1/-1->13->12
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/4/-1->12->-1 [3] 13/4/-1->12->-1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/-1/-1->4->9 [2] 5/0/-1->4->12 [3] 5/0/-1->4->12
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->13
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/-1/-1->10->9 [3] 11/-1/-1->10->9
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] -1/-1/-1->15->14 [3] -1/-1/-1->15->14
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 00 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] -1/-1/-1->11->10 [3] -1/-1/-1->11->10
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/8/-1->0->-1 [2] 1/-1/-1->0->4 [3] 1/-1/-1->0->4
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 00/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 01 : 5[44000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 01/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 00 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 02 : 5[44000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 00 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 00 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 00 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 00 : 1[44000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 00 : 8[3000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 00 : 4[3000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 01 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 00 : 13[44000] -> 14[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 01 : 13[44000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 00 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 00 : 9[44000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 01 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 03 : 5[44000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 01 : 12[3000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 01 : 8[3000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 01 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 01 : 1[44000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 02/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 01 : 9[44000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 02 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 02 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 02 : 13[44000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 01 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 01 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 02 : 8[3000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 02 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 00/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 03/0 : 15[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 03 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 02 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 02 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 03 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 02 : 1[44000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 01/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 02/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 02 : 9[44000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 03 : 13[44000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 03 : 12[3000] -> 13[44000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 02 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 03 : 8[3000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 03 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 03 : 1[44000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 03/0 : 15[c4000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 03 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 03 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 03 : 9[44000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Connected all rings
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Connected all rings
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 00 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Connected all rings
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 00 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Connected all rings
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 00 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 01 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Connected all rings
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 00 : 6[84000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 00 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 02 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 00 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 01 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Connected all rings
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 01 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 01 : 6[84000] -> 5[44000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 00 : 13[44000] -> 12[3000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 00 : 10[84000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 01 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Channel 03 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 01 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 02 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 00 : 14[84000] -> 13[44000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 02 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 02 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 02 : 6[84000] -> 5[44000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 01 : 13[44000] -> 12[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 01 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Channel 03 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 01 : 10[84000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 02 : 2[84000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Channel 03 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 02 : 13[44000] -> 12[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 02 : 10[84000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Channel 03 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Channel 03 : 6[84000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 02 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Channel 03 : 2[84000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Channel 03 : 13[44000] -> 12[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Channel 03 : 14[84000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Channel 03 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO Connected all trees
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO Connected all trees
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 00/0 : 8[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 00/0 : 0[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 01/0 : 8[3000] -> 0[3000] [receive] via NET/IB/1
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 00/0 : 0[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 01/0 : 0[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 01/0 : 0[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 00/0 : 8[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 01/0 : 8[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 00 : 9[44000] -> 8[3000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140538 [3] NCCL INFO comm 0x14ae400090d0 rank 15 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1232:140179:140533 [1] NCCL INFO comm 0x14c91c0090d0 rank 13 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1232:140180:140531 [2] NCCL INFO comm 0x154ebc0090d0 rank 14 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1232:140178:140536 [0] NCCL INFO comm 0x154b140090d0 rank 12 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 01 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 02 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 00 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Channel 03 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 01 : 5[44000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9172 [0] NCCL INFO comm 0x15005c0090d0 rank 0 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1217:8680:9177 [2] NCCL INFO comm 0x1548f00090d0 rank 2 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1217:8681:9179 [3] NCCL INFO comm 0x14f1080090d0 rank 3 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1217:8679:9181 [1] NCCL INFO comm 0x1536cc0090d0 rank 1 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1231:61269:61616 [0] NCCL INFO comm 0x152a6c0090d0 rank 8 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1231:61271:61621 [2] NCCL INFO comm 0x149f580090d0 rank 10 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 02 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61618 [1] NCCL INFO comm 0x1482ec0090d0 rank 9 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1231:61272:61623 [3] NCCL INFO comm 0x146d240090d0 rank 11 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Channel 03 : 5[44000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1218:294540:294890 [0] NCCL INFO comm 0x14ab3c0090d0 rank 4 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1218:294541:294897 [1] NCCL INFO comm 0x1464300090d0 rank 5 nranks 16 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1218:294542:294892 [2] NCCL INFO comm 0x1513580090d0 rank 6 nranks 16 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1218:294543:294895 [3] NCCL INFO comm 0x14cb300090d0 rank 7 nranks 16 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:barrier after loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default1]:rank>0 done waiting for rank 0 before loading kernels
[default2]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default3]:rank>0 done waiting for rank 0 before loading kernels
[default1]:barrier after loading kernels
[default3]:barrier after loading kernels
[default2]:barrier after loading kernels
[default0]:barrier after loading kernels
[default1]:barrier after loading kernels
[default3]:barrier after loading kernels
[default1]:barrier after loading kernels
[default2]:barrier after loading kernels
[default3]:barrier after loading kernels
[default2]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default1]:barrier after loading kernels
[default3]:barrier after loading kernels
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 71.658 seconds
[default0]:time to initialize megatron (seconds): 848.979
[default0]:[after megatron is initialized] datetime: 2023-04-21 12:02:57 
[default0]:building GPT model ...
[default0]:[2023-04-21 12:02:57,197] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-04-21 12:02:57,197] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 12:02:57,198] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.67 GB, percent = 3.1%
[default0]:SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
[default0]:Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=1, model=0): 2, ProcessCoord(pipe=0, data=1, model=1): 3, ProcessCoord(pipe=0, data=2, model=0): 4, ProcessCoord(pipe=0, data=2, model=1): 5, ProcessCoord(pipe=0, data=3, model=0): 6, ProcessCoord(pipe=0, data=3, model=1): 7, ProcessCoord(pipe=0, data=4, model=0): 8, ProcessCoord(pipe=0, data=4, model=1): 9, ProcessCoord(pipe=0, data=5, model=0): 10, ProcessCoord(pipe=0, data=5, model=1): 11, ProcessCoord(pipe=0, data=6, model=0): 12, ProcessCoord(pipe=0, data=6, model=1): 13, ProcessCoord(pipe=0, data=7, model=0): 14, ProcessCoord(pipe=0, data=7, model=1): 15}
[default0]:[2023-04-21 12:03:16,774] [INFO] [module.py:358:_partition_layers] Partitioning pipeline stages with method type:transformer
[default0]:stage=0 layers=9
[default0]:     0: _to_float16
[default0]:     1: EmbeddingPipe
[default0]:     2: <lambda>
[default0]:     3: ParallelTransformerLayerPipe
[default0]:     4: ParallelTransformerLayerPipe
[default0]:     5: undo
[default0]:     6: MixedFusedLayerNorm
[default0]:     7: EmbeddingPipe
[default0]:     8: float16_to_fp32
[default0]:  loss: CrossEntropy
[default0]:[2023-04-21 12:03:16,952] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-04-21 12:03:16,953] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 12:03:16,953] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.67 GB, percent = 3.1%
[default0]:setting training iterations to 39
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-04-21 12:03:16,954] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Trees [0] 2/-1/-1->5->4 [1] -1/-1/-1->5->4
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Trees [0] 3/-1/-1->2->5 [1] 3/0/-1->2->6
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 00 : 2[3000] -> 3[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 00 : 4[3000] -> 5[84000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 00 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 01 : 2[3000] -> 3[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 01 : 0[3000] -> 1[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 00 : 6[3000] -> 7[84000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 01 : 4[3000] -> 5[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 00/0 : 3[c4000] -> 4[44000] [receive] via NET/IB/1
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 00/0 : 5[c4000] -> 6[44000] [receive] via NET/IB/1
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 00/0 : 7[c4000] -> 0[44000] [receive] via NET/IB/1
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Connected all rings
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 01 : 6[3000] -> 7[84000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Channel 00/0 : 3[c4000] -> 4[44000] [send] via NET/IB/1
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 01/0 : 5[c4000] -> 6[44000] [receive] via NET/IB/1
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 00 : 6[44000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 01/0 : 7[c4000] -> 0[44000] [receive] via NET/IB/1
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 00 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Channel 01/0 : 3[c4000] -> 4[44000] [send] via NET/IB/1
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 01/0 : 3[c4000] -> 4[44000] [receive] via NET/IB/1
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 00 : 4[44000] -> 5[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 01 : 6[44000] -> 7[c4000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Channel 00/0 : 7[c4000] -> 0[44000] [send] via NET/IB/1
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Channel 01/0 : 7[c4000] -> 0[44000] [send] via NET/IB/1
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 01 : 0[44000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Channel 00 : 1[84000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Connected all rings
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 01 : 4[44000] -> 5[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Channel 00/0 : 5[c4000] -> 6[44000] [send] via NET/IB/1
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO Channel 00 : 7[84000] -> 6[3000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [send] via NET/IB/0
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Channel 00/0 : 1[c4000] -> 2[44000] [send] via NET/IB/1
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [receive] via NET/IB/0
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Channel 00 : 3[84000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Channel 01 : 1[84000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [receive] via NET/IB/0
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Channel 01/0 : 5[c4000] -> 6[44000] [send] via NET/IB/1
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Channel 01/0 : 1[c4000] -> 2[44000] [send] via NET/IB/1
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Connected all rings
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Channel 01 : 3[84000] -> 2[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO Channel 01 : 7[84000] -> 6[3000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [send] via NET/IB/0
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Connected all rings
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Connected all rings
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Channel 00 : 7[c4000] -> 6[44000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [receive] via NET/IB/0
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 01/0 : 0[44000] -> 2[44000] [send] via NET/IB/1
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [receive] via NET/IB/0
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Channel 01 : 7[c4000] -> 6[44000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 00/0 : 1[c4000] -> 2[44000] [receive] via NET/IB/1
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [send] via NET/IB/0
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Channel 00/0 : 2[44000] -> 5[c4000] [receive] via NET/IB/1
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 00/0 : 4[44000] -> 6[44000] [receive] via NET/IB/1
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [send] via NET/IB/0
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 01/0 : 1[c4000] -> 2[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 00 : 2[44000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 01 : 2[44000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [receive] via NET/IB/0
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Channel 00 : 5[84000] -> 4[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Connected all rings
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Connected all rings
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Channel 01 : 5[84000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 00/0 : 4[44000] -> 6[44000] [send] via NET/IB/1
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Channel 01/0 : 4[44000] -> 3[c4000] [receive] via NET/IB/1
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Channel 00 : 3[c4000] -> 2[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Channel 01 : 3[c4000] -> 2[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[44000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 00/0 : 0[44000] -> 4[44000] [receive] via NET/IB/1
[default2]:n2gpu1232:140180:140601 [2] NCCL INFO comm 0x154e800090d0 rank 7 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 01/0 : 2[44000] -> 6[44000] [receive] via NET/IB/1
[default0]:n2gpu1232:140178:140602 [0] NCCL INFO comm 0x154acc0090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [send] via NET/IB/0
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 00/0 : 4[44000] -> 0[44000] [send] via NET/IB/1
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 01/0 : 6[44000] -> 2[44000] [send] via NET/IB/1
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1231:61271:61687 [2] NCCL INFO comm 0x149f1c0090d0 rank 5 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1231:61269:61686 [0] NCCL INFO comm 0x152a200090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1218:294542:294971 [2] NCCL INFO comm 0x15130c0090d0 rank 3 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1218:294540:294972 [0] NCCL INFO comm 0x14aaf40090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:8678:9268 [0] NCCL INFO comm 0x1500080090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1217:8680:9269 [2] NCCL INFO comm 0x1548b40090d0 rank 1 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 01/0 : 0[44000] -> 2[44000] [receive] via NET/IB/1
[default0]:[2023-04-21 12:03:22,563] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-04-21 12:03:22,569] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-04-21 12:03:22,569] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2023-04-21 12:03:22,569] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-04-21 12:03:22,569] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-04-21 12:03:22,569] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[default0]:[2023-04-21 12:03:22,569] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[default0]:[2023-04-21 12:03:22,569] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[default0]:[2023-04-21 12:03:22,569] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-04-21 12:03:22,569] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 00/0 : 4[44000] -> 0[44000] [receive] via NET/IB/1
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 00/0 : 2[44000] -> 5[c4000] [send] via NET/IB/1
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 00/0 : 0[44000] -> 4[44000] [send] via NET/IB/1
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 01/0 : 6[44000] -> 2[44000] [receive] via NET/IB/1
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Channel 00/0 : 5[c4000] -> 2[44000] [send] via NET/IB/1
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Channel 01/0 : 2[44000] -> 0[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 01/0 : 2[44000] -> 6[44000] [send] via NET/IB/1
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 00/0 : 5[c4000] -> 2[44000] [receive] via NET/IB/1
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Channel 00 : 5[c4000] -> 4[44000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Channel 00/0 : 6[44000] -> 4[44000] [send] via NET/IB/1
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 00/0 : 6[44000] -> 4[44000] [receive] via NET/IB/1
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Channel 01/0 : 2[44000] -> 0[44000] [send] via NET/IB/1
[default0]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Channel 01 : 5[c4000] -> 4[44000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:Building extension module utils...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1232:140179:140600 [1] NCCL INFO comm 0x14c8e00090d0 rank 6 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1232:140181:140599 [3] NCCL INFO comm 0x14adf80090d0 rank 7 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:8679:9266 [1] NCCL INFO comm 0x1536840090d0 rank 0 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO Launch mode Parallel
[default3]:n2gpu1217:8681:9265 [3] NCCL INFO comm 0x14f0d00090d0 rank 1 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:ninja: no work to do.
[default0]:Loading extension module utils...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Channel 01/0 : 4[44000] -> 3[c4000] [send] via NET/IB/1
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO Connected all trees
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Time to load utils op: 1.2950918674468994 seconds
[default0]:Rank: 0 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1231:61272:61685 [3] NCCL INFO comm 0x146cec0090d0 rank 5 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO Connected all trees
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1231:61270:61684 [1] NCCL INFO comm 0x1482a00090d0 rank 4 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default2]:Building extension module utils...
[default2]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default3]:n2gpu1218:294543:294969 [3] NCCL INFO comm 0x14cae80090d0 rank 3 nranks 8 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1218:294541:294970 [1] NCCL INFO comm 0x1463e00090d0 rank 2 nranks 8 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:ninja: no work to do.
[default2]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Time to load utils op: 0.7347226142883301 seconds
[default2]:Rank: 14 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default0]:Time to load utils op: 0.7348871231079102 seconds
[default0]:Rank: 12 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.29321908950805664 seconds
[default1]:Rank: 1 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default2]:Loading extension module utils...
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default3]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Time to load utils op: 0.677609920501709 seconds
[default1]:Rank: 9 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default0]:Time to load utils op: 1.560509204864502 seconds
[default0]:Rank: 8 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default3]:Time to load utils op: 0.7003521919250488 seconds
[default3]:Rank: 11 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default2]:Time to load utils op: 1.5834603309631348 seconds
[default2]:Rank: 10 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default0]:Loading extension module utils...
[default3]:Loading extension module utils...
[default2]:Loading extension module utils...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.2405149936676025 seconds
[default3]:Rank: 3 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 4.925243139266968 seconds
[default2]:Rank: 2 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.0118579864501953 seconds
[default1]:Rank: 13 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.0298821926116943 seconds
[default3]:Rank: 15 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default1]:Time to load utils op: 5.425633907318115 seconds
[default1]:Rank: 5 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default3]:Time to load utils op: 5.392767667770386 seconds
[default3]:Rank: 7 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default0]:Time to load utils op: 5.5931806564331055 seconds
[default0]:Rank: 4 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default2]:Time to load utils op: 5.582536458969116 seconds
[default2]:Rank: 6 partition count [8, 8, 8] and sizes[(25760, False), (64, False), (22, False)] 
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.025672435760498047 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.006802797317504883 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.0034728050231933594 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.002663135528564453 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.01272892951965332 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.033852577209472656 seconds
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.027092933654785156 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.033623456954956055 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.022318363189697266 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.02365589141845703 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.0038373470306396484 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default0]:[2023-04-21 12:03:30,254] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-04-21 12:03:30,338] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 12:03:30,338] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.89 GB, percent = 3.2%
[default0]:[2023-04-21 12:03:30,370] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-04-21 12:03:30,370] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 12:03:30,370] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.89 GB, percent = 3.2%
[default0]:[2023-04-21 12:03:30,370] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[default0]:[2023-04-21 12:03:30,487] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-04-21 12:03:30,487] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-21 12:03:30,488] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 15.89 GB, percent = 3.2%
[default0]:[2023-04-21 12:03:30,488] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-04-21 12:03:30,488] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-04-21 12:03:30,488] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x1500cd9a3d90>
[default0]:[2023-04-21 12:03:30,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   amp_enabled .................. False
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   amp_params ................... False
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-04-21 12:03:30,489] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1500cd784df0>
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   communication_data_type ...... None
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   disable_allgather ............ False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   dump_state ................... False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-04-21 12:03:30,490] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   fp16_enabled ................. True
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   global_rank .................. 0
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 32
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[default0]:[2023-04-21 12:03:30,491] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:[2023-04-21 12:03:30,563] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 4096
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   loss_scale ................... 0
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   memory_breakdown ............. False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   optimizer_name ............... None
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   optimizer_params ............. None
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   pld_enabled .................. False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   pld_params ................... False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   prescale_gradients ........... False
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   scheduler_name ............... None
[default0]:[2023-04-21 12:03:30,564] [INFO] [config.py:957:print]   scheduler_params ............. None
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   sparse_attention ............. None
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   steps_per_print .............. 2000
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   train_batch_size ............. 256
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   world_size ................... 8
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   zero_enabled ................. True
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:957:print]   zero_optimization_stage ...... 1
[default0]:[2023-04-21 12:03:30,565] [INFO] [config.py:943:print_user_config]   json = {
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "train_batch_size": 256, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 1
[default0]:    }, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 12
[default0]:    }, 
[default0]:    "steps_per_print": 2.000000e+03, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0011949539184570312 seconds
[default0]:[2023-04-21 12:03:30,567] [INFO] [engine.py:81:__init__] CONFIG: micro_batches=32 micro_batch_size=1
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.0022020339965820312 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.003609895706176758 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.012925863265991211 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.011994123458862305 seconds
[default2]:NCCL version 2.12.12+cuda11.7
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1217:8680:9294 [2] NCCL INFO comm 0x1548a40090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO Launch mode Parallel
[default3]:n2gpu1217:8681:9295 [3] NCCL INFO comm 0x14f0bc0090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Connected all rings
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Connected all rings
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1232:140181:140624 [3] NCCL INFO comm 0x14adf00090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1232:140180:140620 [2] NCCL INFO comm 0x154e6c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO Launch mode Parallel
[default1]:n2gpu1232:140179:140623 [1] NCCL INFO comm 0x14c8cc0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Connected all rings
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO Connected all trees
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1231:61270:61708 [1] NCCL INFO comm 0x14829c0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61707 [2] NCCL INFO comm 0x149f0c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO Launch mode Parallel
[default0]:n2gpu1232:140178:140622 [0] NCCL INFO comm 0x154abc0090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO Launch mode Parallel
[default3]:n2gpu1231:61272:61709 [3] NCCL INFO comm 0x146cd80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1231:61269:61705 [0] NCCL INFO comm 0x152a100090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1217:8678:9299 [0] NCCL INFO comm 0x1500000090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Launch mode Parallel
[default0]:[2023-04-21 12:03:34,308] [INFO] [engine.py:136:__init__] RANK=0 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=206760 (0.207M) TOTAL_PARAMS=413520 (0.414M) UNIQUE_PARAMS=413520 (0.414M)
[default1]:n2gpu1217:8679:9300 [1] NCCL INFO comm 0x1536780090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:[2023-04-21 12:03:34,389] [INFO] [engine.py:136:__init__] RANK=1 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=206760 (0.207M) TOTAL_PARAMS=413520 (0.414M) UNIQUE_PARAMS=413520 (0.414M)
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Connected all rings
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO Connected all trees
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Connected all rings
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1218:294542:294986 [2] NCCL INFO comm 0x1512fc0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1218:294541:294987 [1] NCCL INFO comm 0x1463dc0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1218:294543:294988 [3] NCCL INFO comm 0x14cae40090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO Launch mode Parallel
[default0]:n2gpu1218:294540:294984 [0] NCCL INFO comm 0x14aae40090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO Launch mode Parallel
[default2]:[2023-04-21 12:03:36,522] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-21 12:03:36,544] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-21 12:03:36,522] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-21 12:03:36,533] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-21 12:03:36,535] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-21 12:03:36,536] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file checkpoints/gpt2-dist 
[default0]:    will not load any checkpoints and will start from random
[default0]:[2023-04-21 12:03:36,522] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-21 12:03:36,543] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-21 12:03:36,544] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-21 12:03:36,559] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-21 12:03:36,523] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-21 12:03:36,571] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-21 12:03:36,552] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-21 12:03:36,554] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-21 12:03:36,580] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:time (ms) | load-checkpoint: 177.32
[default0]:estimated model parameters: 0.00041352
[default0]:estimated model parameters without embeddings: 1.872e-06
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/utils.py:349: UserWarning: Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings
[default0]:  warnings.warn("Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings")
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-04-21 12:03:36 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      10000
[default0]:    validation: 2560
[default0]:    test:       2560
[default0]:> building train, validation, and test datasets for GPT ...
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.018833 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9690) total of 9690 documents
[default0]:    validation:
[default0]:     document indices in [9690, 9990) total of 300 documents
[default0]:    test:
[default0]:     document indices in [9990, 10000) total of 10 documents
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Trees [0] 7/-1/-1->6->4 [1] 7/2/-1->6->-1
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Trees [0] 3/-1/-1->2->5 [1] 3/0/-1->2->6
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Trees [0] 2/-1/-1->5->4 [1] -1/-1/-1->5->4
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Trees [0] 5/6/-1->4->0 [1] 5/-1/-1->4->3
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->2
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/-1/-1->3->2
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 00 : 6[3000] -> 7[84000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 01 : 6[3000] -> 7[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Channel 00/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Channel 00/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Channel 00/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Channel 00/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 00 : 2[3000] -> 3[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 01 : 2[3000] -> 3[84000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 00 : 0[3000] -> 1[84000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 01 : 0[3000] -> 1[84000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Channel 01/0 : 5[84000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 00 : 4[3000] -> 5[84000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 01 : 4[3000] -> 5[84000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Channel 01/0 : 3[84000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Channel 01/0 : 7[84000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Channel 01/0 : 1[84000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Channel 00 : 1[84000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Channel 00 : 7[84000] -> 6[3000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Channel 01 : 1[84000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Channel 01 : 7[84000] -> 6[3000] via P2P/IPC/read
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [receive] via NET/IB/0
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Channel 00 : 3[84000] -> 2[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Channel 01 : 3[84000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 00/0 : 2[3000] -> 5[84000] [send] via NET/IB/0
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 01/0 : 6[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 01/0 : 2[3000] -> 6[3000] [send] via NET/IB/0
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 00/0 : 5[84000] -> 2[3000] [receive] via NET/IB/0
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Channel 00 : 5[84000] -> 4[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Channel 01 : 5[84000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[84000] [send] via NET/IB/0
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1232:140180:140634 [2] NCCL INFO comm 0x154e680090d0 rank 7 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1232:140178:140635 [0] NCCL INFO comm 0x154ab00090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1231:61271:61719 [2] NCCL INFO comm 0x149f000090d0 rank 5 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1231:61269:61720 [0] NCCL INFO comm 0x152a040090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1217:8680:9311 [2] NCCL INFO comm 0x1548980090d0 rank 1 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:8678:9310 [0] NCCL INFO comm 0x14fffc0090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1218:294542:294998 [2] NCCL INFO comm 0x1512f80090d0 rank 3 nranks 8 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1218:294540:294999 [0] NCCL INFO comm 0x14aae43205c0 rank 2 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1217:8680:9317 [2] NCCL INFO comm 0x1548940090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:8678:9319 [0] NCCL INFO comm 0x14ffe80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_sample_idx.npy
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Connected all rings
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1231:61271:61728 [2] NCCL INFO comm 0x149ef00090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1231:61269:61726 [0] NCCL INFO comm 0x1529f00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Connected all rings
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1232:140180:140643 [2] NCCL INFO comm 0x154e640090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:140178:140641 [0] NCCL INFO comm 0x154a9c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.050 seconds
[default0]:    total number of samples: 56335
[default0]:    total number of epochs: 1
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (731) is smaller than 95.0% of number of samples per epoch (1829), setting separate_last_epoch to True
[default0]:n2gpu1218:294540:295005 [0] NCCL INFO comm 0x14aac40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1218:294542:295007 [2] NCCL INFO comm 0x1512f40090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.055573
[default0]:    using:
[default0]:     number of documents:       300
[default0]:     number of epochs:          2
[default0]:     sequence length:           512
[default0]:     total number of samples:   3659
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.822191
[default0]: > building shuffle index with split [0, 1829) and [1829, 3659) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.059754
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_2560ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_2560ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_2560ns_512sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.106 seconds
[default0]:    total number of samples: 3660
[default0]:    total number of epochs: 2
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (18) is smaller than 95.0% of number of samples per epoch (63), setting separate_last_epoch to True
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.076685
[default0]:    using:
[default0]:     number of documents:       10
[default0]:     number of epochs:          41
[default0]:     sequence length:           512
[default0]:     total number of samples:   2605
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.058079
[default0]: > building shuffle index with split [0, 2542) and [2542, 2605) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.065870
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_2560ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_2560ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_2560ns_512sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.012 seconds
[default0]:    total number of samples: 2606
[default0]:    total number of epochs: 41
[default0]:> finished creating GPT datasets ...
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 00/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 01/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 02/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 03/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 04/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 05/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 06/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 07/08 :    0   1
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 00/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 01/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 02/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 03/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 04/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 05/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 06/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 07/08 :    0   1
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 00 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 00 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 01 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 01 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 02 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 02 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default1]:n2gpu1217:8679:9327 [1] NCCL INFO comm 0x1536700090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1217:8678:9326 [0] NCCL INFO comm 0x14ffd80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 03 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 04 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1217:8680:9330 [2] NCCL INFO comm 0x15487c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO Launch mode Parallel
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1217:8681:9331 [3] NCCL INFO comm 0x14f0b40090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 04 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 03 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO Launch mode Parallel
[default3]:n2gpu1232:140181:140653 [3] NCCL INFO comm 0x14ade80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 04 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Connected all rings
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO Connected all trees
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 05 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Connected all rings
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1232:140179:140654 [1] NCCL INFO comm 0x14c8c40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1232:140180:140649 [2] NCCL INFO comm 0x154e580090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO Launch mode Parallel
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1232:140178:140651 [0] NCCL INFO comm 0x154a900090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 05 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1231:61270:61738 [1] NCCL INFO comm 0x1482940090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Connected all rings
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1231:61269:61734 [0] NCCL INFO comm 0x1529e40090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 04 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 06 : 0[3000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 05 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default2]:n2gpu1231:61271:61736 [2] NCCL INFO comm 0x149ee40090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1231:61272:61739 [3] NCCL INFO comm 0x146cd00090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 06 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 05 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 06 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Channel 07 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Channel 07 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 06 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Channel 07 : 1[c4000] -> 0[84000] via P2P/IPC/read
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Channel 07 : 0[84000] -> 1[c4000] via P2P/IPC/read
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Connected all rings
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default0]:n2gpu1218:294540:295014 [0] NCCL INFO comm 0x14aab80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO Launch mode Parallel
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Connected all rings
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO Connected all trees
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO 8 coll channels, 8 p2p channels, 8 p2p channels per peer
[default3]:n2gpu1218:294543:295018 [3] NCCL INFO comm 0x14cadc0090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1218:294542:295016 [2] NCCL INFO comm 0x1512dc0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO Launch mode Parallel
[default1]:n2gpu1218:294541:295017 [1] NCCL INFO comm 0x1463d40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO Launch mode Parallel
[default0]:[after dataloaders are built] datetime: 2023-04-21 12:04:00 
[default0]:done with setup ...
[default0]:training ...
[default0]:Number of parameters: [tensor rank - pipeline rank] w/ and w/o embeddings:
[default0]:[000-000] 0.0004B / 0.0000B
[default3]:time (ms) | model-and-optimizer-setup: 39692.86 | train/valid/test-data-iterators-setup: 10635.01
[default1]:[001-000] 0.0004B / 0.0000B
[default0]:[before the start of training step] datetime: 2023-04-21 12:04:00 
[default0]:[2023-04-21 12:04:00,879] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[default0]:[2023-04-21 12:04:00,879] [INFO] [checkpointing.py:530:forward] ----Partition Activations True, CPU CHECKPOINTING False
[default0]:[2023-04-21 12:04:00,879] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 2 total layers
[default0]:[2023-04-21 12:04:00,879] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[default0]:[2023-04-21 12:04:00,879] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[default3]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Connected all rings
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO Connected all trees
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Connected all rings
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO Connected all trees
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Connected all rings
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO Connected all trees
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1218:294542:295869 [2] NCCL INFO comm 0x1512600090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Connected all rings
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO Connected all trees
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1231:61271:62590 [2] NCCL INFO comm 0x149e600090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1231:61270:62593 [1] NCCL INFO comm 0x1482400090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Connected all rings
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO Connected all trees
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Connected all rings
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO Connected all trees
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1218:294540:295872 [0] NCCL INFO comm 0x14aa340090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Connected all rings
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO Connected all trees
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1231:61269:62595 [0] NCCL INFO comm 0x1529640090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Connected all rings
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO Connected all trees
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:8678:10181 [0] NCCL INFO comm 0x14ff5c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1217:8679:10185 [1] NCCL INFO comm 0x1536240090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Connected all rings
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO Connected all trees
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1217:8680:10179 [2] NCCL INFO comm 0x1547fc0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Connected all rings
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO Connected all trees
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Connected all rings
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO Connected all trees
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1218:294543:295874 [3] NCCL INFO comm 0x14ca840090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Connected all rings
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO Connected all trees
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1231:61272:62596 [3] NCCL INFO comm 0x146c8c0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1217:8681:10183 [3] NCCL INFO comm 0x14f0700090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1232:140181:141508 [3] NCCL INFO comm 0x14ad980090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1232:140180:141505 [2] NCCL INFO comm 0x154dd40090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1232:140178:141507 [0] NCCL INFO comm 0x154a0c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1232:140179:141510 [1] NCCL INFO comm 0x14c8740090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Connected all rings
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO Connected all trees
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1218:294541:295881 [1] NCCL INFO comm 0x14637c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:[Rank 1] (after 10 iterations) memory (MB) | allocated: 101.49072265625 | max allocated: 176.82177734375 | reserved: 184.0 | max reserved: 184.0
[default3]: iteration       10/      39 | consumed samples:         2560 | consumed tokens:      1310720 | elapsed time per iteration (s): 28.13 | learning rate: 1.000E-06 | global batch size:   256 | lm loss: 1.082925E+01 | loss scale: 4096.0 | grad norm: 0.271 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 9.101 | TFLOPs: 0.00 |
[default0]:[Rank 0] (after 10 iterations) memory (MB) | allocated: 101.49072265625 | max allocated: 176.82177734375 | reserved: 184.0 | max reserved: 184.0
[default3]: iteration       20/      39 | consumed samples:         5120 | consumed tokens:      2621440 | elapsed time per iteration (s): 29.27 | learning rate: 1.000E-06 | global batch size:   256 | lm loss: 1.082933E+01 | loss scale: 4096.0 | grad norm: 0.288 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 8.745 | TFLOPs: 0.00 |
[default3]: iteration       30/      39 | consumed samples:         7680 | consumed tokens:      3932160 | elapsed time per iteration (s): 26.74 | learning rate: 1.000E-06 | global batch size:   256 | lm loss: 1.082918E+01 | loss scale: 4096.0 | grad norm: 0.266 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 9.573 | TFLOPs: 0.00 |
[default0]:saving checkpoint at iteration      39 to checkpoints/gpt2-dist
[default3]:------------------------------------------------------------------------------------------------------------
[default3]:valid loss at the end of training for val data | lm loss value: 1.082939E+01 | lm loss PPL: 5.048274E+04 | 
[default3]:------------------------------------------------------------------------------------------------------------
[default0]:[2023-04-21 12:23:35,246] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step39 is about to be saved!
[default0]:[2023-04-21 12:23:35,424] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_01-model_00-model_states.pt...
[default0]:[2023-04-21 12:23:35,490] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_01-model_00-model_states.pt.
[default0]:[2023-04-21 12:23:35,491] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_03-model_00-model_states.pt...
[default0]:[2023-04-21 12:23:35,500] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_03-model_00-model_states.pt.
[default0]:[2023-04-21 12:23:35,500] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_04-model_00-model_states.pt...
[default0]:[2023-04-21 12:23:35,506] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_04-model_00-model_states.pt.
[default0]:[2023-04-21 12:23:35,506] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_06-model_00-model_states.pt...
[default0]:[2023-04-21 12:23:35,509] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_06-model_00-model_states.pt.
[default0]:[2023-04-21 12:23:35,509] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-dist/global_step39/mp_rank_00_model_states.pt
[default0]:[2023-04-21 12:23:35,509] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/mp_rank_00_model_states.pt...
[default0]:[2023-04-21 12:23:35,535] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/mp_rank_00_model_states.pt.
[default1]:[2023-04-21 12:23:35,501] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_01-model_01-model_states.pt.
[default1]:[2023-04-21 12:23:35,501] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_03-model_01-model_states.pt...
[default1]:[2023-04-21 12:23:35,504] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_03-model_01-model_states.pt.
[default1]:[2023-04-21 12:23:35,505] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_04-model_01-model_states.pt...
[default1]:[2023-04-21 12:23:35,508] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_04-model_01-model_states.pt.
[default1]:[2023-04-21 12:23:35,508] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/layer_06-model_01-model_states.pt...
[default1]:[2023-04-21 12:23:35,521] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/layer_06-model_01-model_states.pt.
[default1]:[2023-04-21 12:23:35,521] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: checkpoints/gpt2-dist/global_step39/mp_rank_01_model_states.pt
[default1]:[2023-04-21 12:23:35,521] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/mp_rank_01_model_states.pt...
[default1]:[2023-04-21 12:23:35,524] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/mp_rank_01_model_states.pt.
[default3]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_3_mp_rank_01_optim_states.pt...
[default0]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default0]:[2023-04-21 12:23:36,562] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 12:23:36,562] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 12:23:36,562] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default2]:[2023-04-21 12:23:36,557] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default2]:[2023-04-21 12:23:36,572] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default2]:[2023-04-21 12:23:36,572] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default2]:[2023-04-21 12:23:36,572] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default0]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default2]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[default3]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_1_mp_rank_01_optim_states.pt...
[default3]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_7_mp_rank_01_optim_states.pt...
[default2]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_7_mp_rank_00_optim_states.pt...
[default1]:[2023-04-21 12:23:36,555] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_0_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 12:23:36,559] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_0_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 12:23:36,559] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_0_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 12:23:36,559] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default1]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_4_mp_rank_01_optim_states.pt...
[default1]:[2023-04-21 12:23:36,560] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_4_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 12:23:36,561] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_4_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 12:23:36,561] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default0]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_4_mp_rank_00_optim_states.pt...
[default0]:[2023-04-21 12:23:36,615] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_4_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 12:23:36,615] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_4_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 12:23:36,615] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default3]:[2023-04-21 12:23:36,557] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_5_mp_rank_01_optim_states.pt...
[default3]:[2023-04-21 12:23:36,599] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_5_mp_rank_01_optim_states.pt.
[default3]:[2023-04-21 12:23:36,599] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_5_mp_rank_01_optim_states.pt
[default3]:[2023-04-21 12:23:36,599] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default2]:[2023-04-21 12:23:36,556] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step39/zero_pp_rank_5_mp_rank_00_optim_states.pt...
[default2]:[2023-04-21 12:23:36,576] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_5_mp_rank_00_optim_states.pt.
[default2]:[2023-04-21 12:23:36,576] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_5_mp_rank_00_optim_states.pt
[default2]:[2023-04-21 12:23:36,576] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default3]:[2023-04-21 12:23:36,583] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_3_mp_rank_01_optim_states.pt.
[default3]:[2023-04-21 12:23:36,584] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_3_mp_rank_01_optim_states.pt
[default3]:[2023-04-21 12:23:36,584] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default0]:[2023-04-21 12:23:36,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default2]:[2023-04-21 12:23:36,620] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default2]:[2023-04-21 12:23:36,620] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default2]:[2023-04-21 12:23:36,620] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default3]:[2023-04-21 12:23:36,632] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_1_mp_rank_01_optim_states.pt.
[default3]:[2023-04-21 12:23:36,632] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_1_mp_rank_01_optim_states.pt
[default3]:[2023-04-21 12:23:36,632] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default0]:[2023-04-21 12:23:36,747] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 12:23:36,747] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default3]:[2023-04-21 12:23:37,582] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_7_mp_rank_01_optim_states.pt.
[default3]:[2023-04-21 12:23:37,582] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_7_mp_rank_01_optim_states.pt
[default3]:[2023-04-21 12:23:37,582] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default2]:[2023-04-21 12:23:37,571] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_7_mp_rank_00_optim_states.pt.
[default2]:[2023-04-21 12:23:37,571] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_7_mp_rank_00_optim_states.pt
[default2]:[2023-04-21 12:23:37,571] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default1]:[2023-04-21 12:23:37,598] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_6_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 12:23:37,598] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_6_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 12:23:37,598] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default1]:[2023-04-21 12:23:37,530] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_2_mp_rank_01_optim_states.pt.
[default1]:[2023-04-21 12:23:37,530] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_2_mp_rank_01_optim_states.pt
[default1]:[2023-04-21 12:23:37,530] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default0]:[2023-04-21 12:23:37,564] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_6_mp_rank_00_optim_states.pt.
[default0]:[2023-04-21 12:23:37,564] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step39/zero_pp_rank_6_mp_rank_00_optim_states.pt
[default0]:[2023-04-21 12:23:37,564] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step39 is ready now!
[default0]:  successfully saved checkpoint at iteration      39 to checkpoints/gpt2-dist
[default3]:------------------------------------------------------------------------------------------------------------
[default3]:test loss at the end of training for test data | lm loss value: 1.082971E+01 | lm loss PPL: 5.049911E+04 | 
[default3]:------------------------------------------------------------------------------------------------------------
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO comm 0x1536cc0090d0 rank 1 nranks 16 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1217:8679:9301 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO comm 0x1536780090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1217:8679:10188 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO comm 0x1536240090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1217:8679:9335 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1217:8681:9188 [3] NCCL INFO [Service thread] Connection closed by localRank 3
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO comm 0x14f1080090d0 rank 3 nranks 16 cudaDev 3 busId c4000 - Abort COMPLETE
[default2]:n2gpu1217:8680:9187 [2] NCCL INFO [Service thread] Connection closed by localRank 2
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO comm 0x1548f00090d0 rank 2 nranks 16 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1217:8680:9297 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO comm 0x1548a40090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1217:8680:10189 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO comm 0x1547fc0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1217:8680:9333 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO comm 0x15487c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1217:8680:9320 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1217:8679:8679 [1] NCCL INFO comm 0x1536700090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default3]:n2gpu1217:8681:9296 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO comm 0x14f0bc0090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1217:8681:10186 [3] NCCL INFO [Service thread] Connection closed by localRank 0
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO comm 0x14f0700090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1217:8681:9334 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1217:8681:8681 [3] NCCL INFO comm 0x14f0b40090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO comm 0x1548940090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1217:8680:9312 [2] NCCL INFO [Service thread] Connection closed by localRank 1
[default2]:n2gpu1217:8680:8680 [2] NCCL INFO comm 0x1548980090d0 rank 1 nranks 8 cudaDev 2 busId 84000 - Abort COMPLETE
[default3]:n2gpu1232:140181:140545 [3] NCCL INFO [Service thread] Connection closed by localRank 3
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO comm 0x14ae400090d0 rank 15 nranks 16 cudaDev 3 busId c4000 - Abort COMPLETE
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO comm 0x15005c0090d0 rank 0 nranks 16 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1217:8678:9302 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO comm 0x1500000090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1217:8678:10187 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO comm 0x14ff5c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1217:8678:9332 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO comm 0x14ffd80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1217:8678:9321 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO comm 0x14ffe80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1217:8678:9313 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1217:8678:8678 [0] NCCL INFO comm 0x14fffc0090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default3]:n2gpu1232:140181:140626 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO comm 0x14adf00090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1232:140181:141513 [3] NCCL INFO [Service thread] Connection closed by localRank 0
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO comm 0x14ad980090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1232:140181:140656 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1232:140181:140181 [3] NCCL INFO comm 0x14ade80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO comm 0x14c91c0090d0 rank 13 nranks 16 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1232:140179:140628 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO comm 0x14c8cc0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1232:140179:141517 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO comm 0x154ebc0090d0 rank 14 nranks 16 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1232:140180:140627 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO comm 0x154b140090d0 rank 12 nranks 16 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1232:140178:140625 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO comm 0x154abc0090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO comm 0x14c8740090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1232:140179:140658 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1232:140179:140179 [1] NCCL INFO comm 0x14c8c40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO comm 0x154e6c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1232:140180:141511 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO comm 0x154dd40090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1232:140180:140655 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO comm 0x154e580090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1232:140180:140645 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO comm 0x154e640090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1232:140180:140636 [2] NCCL INFO [Service thread] Connection closed by localRank 1
[default2]:n2gpu1232:140180:140180 [2] NCCL INFO comm 0x154e680090d0 rank 7 nranks 8 cudaDev 2 busId 84000 - Abort COMPLETE
[default0]:n2gpu1232:140178:141512 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO comm 0x154a0c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1232:140178:140657 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO comm 0x154a900090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1232:140178:140644 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO comm 0x154a9c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1232:140178:140637 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1232:140178:140178 [0] NCCL INFO comm 0x154ab00090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1231:61269:61629 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1231:61271:61631 [2] NCCL INFO [Service thread] Connection closed by localRank 2
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO comm 0x149f580090d0 rank 10 nranks 16 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1231:61271:61711 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO comm 0x149f0c0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1231:61271:62597 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO comm 0x149e600090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1231:61271:61743 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO comm 0x149ee40090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1231:61271:61731 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO comm 0x149ef00090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1231:61271:61722 [2] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1231:61270:61712 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO comm 0x14829c0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1231:61270:62598 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO comm 0x1482400090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1231:61270:61742 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1231:61270:61270 [1] NCCL INFO comm 0x1482940090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default3]:n2gpu1231:61272:61710 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO comm 0x146cd80090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1231:61272:62599 [3] NCCL INFO [Service thread] Connection closed by localRank 0
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO comm 0x146c8c0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1231:61272:61741 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1231:61272:61272 [3] NCCL INFO comm 0x146cd00090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO comm 0x152a6c0090d0 rank 8 nranks 16 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1231:61269:61713 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO comm 0x152a100090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1231:61269:62600 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO comm 0x1529640090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1231:61269:61740 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO comm 0x1529e40090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1231:61269:61729 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO comm 0x1529f00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1231:61269:61721 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1231:61269:61269 [0] NCCL INFO comm 0x152a040090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default2]:n2gpu1231:61271:61271 [2] NCCL INFO comm 0x149f000090d0 rank 5 nranks 8 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1218:294542:294898 [2] NCCL INFO [Service thread] Connection closed by localRank 2
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO comm 0x1513580090d0 rank 6 nranks 16 cudaDev 2 busId 84000 - Abort COMPLETE
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO comm 0x14cb300090d0 rank 7 nranks 16 cudaDev 3 busId c4000 - Abort COMPLETE
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO comm 0x14ab3c0090d0 rank 4 nranks 16 cudaDev 0 busId 3000 - Abort COMPLETE
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO comm 0x1464300090d0 rank 5 nranks 16 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1218:294541:294991 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO comm 0x1463dc0090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1218:294541:295882 [1] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:294540:294989 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO comm 0x14aae40090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:294540:295877 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO comm 0x14aa340090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:294540:295022 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO comm 0x14aab80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:294540:295009 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1218:294542:294990 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO comm 0x1512fc0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1218:294542:295875 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO comm 0x1512600090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1218:294542:295021 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO comm 0x1512dc0090d0 rank 0 nranks 2 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1218:294542:295008 [2] NCCL INFO [Service thread] Connection closed by localRank 0
[default3]:n2gpu1218:294543:294992 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO comm 0x14cae40090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1218:294543:295878 [3] NCCL INFO [Service thread] Connection closed by localRank 0
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO comm 0x14ca840090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Abort COMPLETE
[default3]:n2gpu1218:294543:295020 [3] NCCL INFO [Service thread] Connection closed by localRank 1
[default3]:n2gpu1218:294543:294543 [3] NCCL INFO comm 0x14cadc0090d0 rank 1 nranks 2 cudaDev 3 busId c4000 - Abort COMPLETE
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO comm 0x14637c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Abort COMPLETE
[default1]:n2gpu1218:294541:295019 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[default1]:n2gpu1218:294541:294541 [1] NCCL INFO comm 0x1463d40090d0 rank 1 nranks 2 cudaDev 1 busId 44000 - Abort COMPLETE
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO comm 0x14aac40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1218:294540:295001 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1218:294540:294540 [0] NCCL INFO comm 0x14aae43205c0 rank 2 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO comm 0x1512f40090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Abort COMPLETE
[default2]:n2gpu1218:294542:295000 [2] NCCL INFO [Service thread] Connection closed by localRank 1
[default2]:n2gpu1218:294542:294542 [2] NCCL INFO comm 0x1512f80090d0 rank 3 nranks 8 cudaDev 2 busId 84000 - Abort COMPLETE
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'n2gpu1232.ab2021.local_140149_0' has failed to shutdown the rendezvous '1234' due to an error of type RendezvousConnectionError.
