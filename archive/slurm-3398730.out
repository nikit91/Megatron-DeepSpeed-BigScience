cpu-bind=MASK - n2gpu1201, task  0  0 [62938]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 1 --nnodes 10 --rdzv_id=1234 --rdzv_endpoint n2gpu1201:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 2 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 2 --hidden-size 8 --num-attention-heads 2 --seq-length 512 --max-position-embeddings 512 --micro-batch-size 1 --rampup-batch-size 2 2 1_000 --global-batch-size 16 --train-samples 10_000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --lr-warmup-samples 5 --min-lr 1e-6 --lr-decay-style cosine --lr-decay-samples 12 --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 100 --log-interval 10 --save-interval 50 --eval-interval 100 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-dist --load checkpoints/gpt2-dist --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --zero-stage 1 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1201, task  0  0 [63047]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1204, task  3  0 [31680]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1203, task  2  0 [32367]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1209, task  8  0 [30957]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1208, task  7  0 [31079]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1210, task  9  0 [31072]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1206, task  5  0 [31115]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1207, task  6  0 [31074]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1205, task  4  0 [30937]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1202, task  1  0 [38391]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:using world size: 10, data-parallel-size: 5, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  abort_on_unmet_fused_kernel_constraints ......... False
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  bert_binary_head ................................ True
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  clip_grad ....................................... 1.0
[default0]:  codecarbon_dir .................................. None
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  curriculum_learning ............................. False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_size .............................. 5
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distributed_backend ............................. nccl
[default0]:  embed_layernorm ................................. False
[default0]:  embedding_path .................................. None
[default0]:  encoder_seq_length .............................. 512
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 100
[default0]:  eval_iters ...................................... 10
[default0]:  eval_only ....................................... None
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 100
[default0]:  ffn_hidden_size ................................. 32
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  gigaflos_no_embeds .............................. 0
[default0]:  global_batch_size ............................... 16
[default0]:  glu_activation .................................. None
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 8
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_dim ......................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  kill_switch_path ................................ None
[default0]:  kv_channels ..................................... 4
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-dist
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 10
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_level ....................................... None
[default0]:  log_level_replica ............................... None
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_params_norm ................................. False
[default0]:  log_path ........................................ None
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  loss_on_targets_only ............................ False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ 12
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 5
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_prob ....................................... 0.15
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 512
[default0]:  mean_noise_span_length .......................... None
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mmap_warmup ..................................... False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  noise_density ................................... None
[default0]:  num_attention_heads ............................. 2
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_layers ...................................... 2
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  override_lr_scheduler ........................... False
[default0]:  pad_vocab_size_to ............................... None
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  position_embedding_type ......................... PositionEmbeddingType.absolute
[default0]:  pp_partition_method ............................. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... ['2', '2', '1_000']
[default0]:  rank ............................................ 0
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  reweight_loss_based_on_position_frequency ....... False
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-dist
[default0]:  save_interval ................................... 50
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 512
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train_iteration_range ...................... None
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  sync_tp_duplicated_parameters ................... False
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 2
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  test_weighted_split_names ....................... None
[default0]:  test_weighted_split_paths ....................... None
[default0]:  test_weighted_split_paths_path .................. None
[default0]:  test_weighted_split_splits ...................... None
[default0]:  test_weighted_split_weights ..................... None
[default0]:  tile_factor ..................................... 1
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_name_or_path .......................... None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  train_iters ..................................... None
[default0]:  train_samples ................................... 10000
[default0]:  train_tokens .................................... None
[default0]:  train_weighted_split_paths ...................... None
[default0]:  train_weighted_split_paths_path ................. None
[default0]:  universal_checkpoint ............................ False
[default0]:  use_bnb_optimizer ............................... False
[default0]:  use_checkpoint_lr_scheduler ..................... False
[default0]:  use_contiguous_buffers_in_ddp ................... False
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  valid_num_workers ............................... 2
[default0]:  valid_weighted_split_names ...................... None
[default0]:  valid_weighted_split_paths ...................... None
[default0]:  valid_weighted_split_paths_path ................. None
[default0]:  valid_weighted_split_splits ..................... None
[default0]:  valid_weighted_split_weights .................... None
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  weight_decay .................................... 0.1
[default0]:  world_size ...................................... 10
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 1
[default0]:-------------------- end of arguments ---------------------
[default0]:will use batch size rampup starting from global batch size 2 to global batch size 16 with batch size increments 2 over 1000 samples.
[default0]:> building GPT2BPETokenizer tokenizer ...
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]: > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=e52bdab git_branch=main ****
[default0]:> initializing torch distributed ...
[default0]:[2023-04-19 15:30:20,886] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:> initializing tensor model parallel with size 2
[default0]:> initializing pipeline model parallel with size 1
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:> setting random seeds to 42 ...
[default0]:[2023-04-19 15:30:44,557] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.113 seconds
[default0]:WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_upper_triang_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o scaled_upper_triang_masked_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -o scaled_upper_triang_masked_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_upper_triang_masked_softmax.o scaled_upper_triang_masked_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_upper_triang_masked_softmax_cuda.so
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -o scaled_masked_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_masked_softmax.o scaled_masked_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_masked_softmax_cuda.so
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module fused_mix_prec_layer_norm_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -maxrregcount=50 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu -o layer_norm_cuda_kernel.cuda.o 
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In function ‘void cuda_layer_norm(at::Tensor*, at::Tensor*, at::Tensor*, at::Tensor*, int, int, c10::IntList, at::Tensor*, at::Tensor*, double)’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:223: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                               ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:246: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:271: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                               ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:295: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:358: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:413: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                             ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:118: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:141: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                             ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:166: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:190: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:257: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:316: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                            ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:130: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:153: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:178: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:202: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:273: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:336: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:150: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:173: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                             ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:198: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:226: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:293: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:352: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:165: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:188: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                            ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:213: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:245: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:316: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                            ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:706:379: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  706 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                           ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In function ‘void cuda_layer_norm_gradient(at::Tensor*, at::Tensor*, at::Tensor*, at::Tensor*, int, int, c10::IntList, at::Tensor*, at::Tensor*, double, at::Tensor*, at::Tensor*, at::Tensor*)’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:223: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                               ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:246: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:271: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                               ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:332: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                            ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:388: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                    ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:437: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:488: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:549: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:119: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:142: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:167: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:232: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                        ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:292: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                    ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:341: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                     ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:396: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                            ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:461: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:131: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                   ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:154: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:179: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                   ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:248: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                        ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:312: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                        ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:361: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:420: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                    ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:489: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:151: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:174: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:199: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:264: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                        ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:324: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                    ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:377: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:432: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:497: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:166: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:189: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                             ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:214: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                      ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:283: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                           ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:347: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                           ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:404: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                    ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:463: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:532: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  814 |     DISPATCH_FLOAT_HALF_AND_BFLOAT_INOUT_TYPES(
[default0]:      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In instantiation of ‘void HostLayerNormGradient(const V*, const U*, const U*, at::Tensor*, int, int, const V*, const V*, double, T*, V*, V*) [with T = float; U = float; V = float]’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:203:   required from here
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:138: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:210: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:247: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:137: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:174: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:782:129: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  782 |     cuComputeGradInput<<<blocks1, threads1, nshared, stream>>>(
[default0]:      |                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In instantiation of ‘void HostLayerNormGradient(const V*, const U*, const U*, at::Tensor*, int, int, const V*, const V*, double, T*, V*, V*) [with T = float; U = float; V = c10::Half]’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:95:   required from here
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:138: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:210: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:247: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:137: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:174: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:782:129: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  782 |     cuComputeGradInput<<<blocks1, threads1, nshared, stream>>>(
[default0]:      |                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In instantiation of ‘void HostLayerNormGradient(const V*, const U*, const U*, at::Tensor*, int, int, const V*, const V*, double, T*, V*, V*) [with T = float; U = float; V = c10::BFloat16]’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:103:   required from here
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:138: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:210: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:247: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:137: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:174: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:782:129: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  782 |     cuComputeGradInput<<<blocks1, threads1, nshared, stream>>>(
[default0]:      |                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In instantiation of ‘void HostLayerNormGradient(const V*, const U*, const U*, at::Tensor*, int, int, const V*, const V*, double, T*, V*, V*) [with T = c10::Half; U = float; V = c10::Half]’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:127:   required from here
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:138: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:210: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:247: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:137: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:174: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:782:129: warning: ‘T* at::Tensor::data() const [with T = c10::Half]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  782 |     cuComputeGradInput<<<blocks1, threads1, nshared, stream>>>(
[default0]:      |                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu: In instantiation of ‘void HostLayerNormGradient(const V*, const U*, const U*, at::Tensor*, int, int, const V*, const V*, double, T*, V*, V*) [with T = c10::BFloat16; U = float; V = c10::BFloat16]’:
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:814:138:   required from here
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:138: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                          ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:210: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                  ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:751:247: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  751 |       cuComputePartGradGammaBeta<<<blocks2, threads2, nshared2, stream>>>(
[default0]:      |                                                                                                                                                                                                                                                       ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:137: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                         ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:764:174: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  764 |       cuComputeGradGammaBeta<<<blocks3, threads3, nshared3, stream>>>(
[default0]:      |                                                                                                                                                                              ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/layer_norm_cuda_kernel.cu:782:129: warning: ‘T* at::Tensor::data() const [with T = c10::BFloat16]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
[default0]:  782 |     cuComputeGradInput<<<blocks1, threads1, nshared, stream>>>(
[default0]:      |                                                                                                                                 ^ 
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:235:1: note: declared here
[default0]:  235 |   T * data() const {
[default0]:      | ^ ~~
[default0]:[3/3] c++ layer_norm_cuda.o layer_norm_cuda_kernel.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o fused_mix_prec_layer_norm_cuda.so
[default0]:Loading extension module fused_mix_prec_layer_norm_cuda...
[default0]:rank 0 finished kernel load
[default0]:n2gpu1201:63080:63080 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.69<0>
[default0]:n2gpu1201:63080:63080 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1201:63080:63080 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.69<0>
[default0]:n2gpu1201:63080:63080 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1202:38404:38404 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.70<0>
[default0]:n2gpu1203:32381:32381 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.71<0>
[default0]:n2gpu1209:30977:30977 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.77<0>
[default0]:n2gpu1207:31095:31095 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.75<0>
[default0]:n2gpu1205:30956:30956 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.73<0>
[default0]:n2gpu1206:31134:31134 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.74<0>
[default0]:n2gpu1208:31099:31099 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.76<0>
[default0]:n2gpu1210:31092:31092 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.78<0>
[default0]:n2gpu1202:38404:38404 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1202:38404:38404 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.70<0>
[default0]:n2gpu1202:38404:38404 [0] NCCL INFO Using network IB
[default0]:n2gpu1206:31134:31134 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1203:32381:32381 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1203:32381:32381 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.71<0>
[default0]:n2gpu1203:32381:32381 [0] NCCL INFO Using network IB
[default0]:n2gpu1207:31095:31095 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1207:31095:31095 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.75<0>
[default0]:n2gpu1207:31095:31095 [0] NCCL INFO Using network IB
[default0]:n2gpu1208:31099:31099 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1208:31099:31099 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.76<0>
[default0]:n2gpu1208:31099:31099 [0] NCCL INFO Using network IB
[default0]:n2gpu1206:31134:31134 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.74<0>
[default0]:n2gpu1206:31134:31134 [0] NCCL INFO Using network IB
[default0]:n2gpu1205:30956:30956 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1210:31092:31092 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1210:31092:31092 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.78<0>
[default0]:n2gpu1210:31092:31092 [0] NCCL INFO Using network IB
[default0]:n2gpu1205:30956:30956 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.73<0>
[default0]:n2gpu1205:30956:30956 [0] NCCL INFO Using network IB
[default0]:n2gpu1204:31693:31693 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1204:31693:31693 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.72<0>
[default0]:n2gpu1204:31693:31693 [0] NCCL INFO Using network IB
[default0]:n2gpu1209:30977:30977 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1209:30977:30977 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.77<0>
[default0]:n2gpu1209:30977:30977 [0] NCCL INFO Using network IB
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->3
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Trees [0] 4/9/-1->8->0 [1] -1/-1/-1->8->7
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 4/2/-1->3->5
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->7
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 00/0 : 5[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 8/6/-1->7->5
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 00/0 : 6[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 7/3/-1->5->1
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 00/0 : 4[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->3
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Trees [0] -1/-1/-1->9->8 [1] 1/-1/-1->9->-1
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 00/0 : 8[3000] -> 9[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 5/0/-1->1->9
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 00/0 : 9[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 01/0 : 9[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 7[3000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 01/0 : 5[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 01/0 : 6[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 4[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 00/0 : 5[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 3[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 01/0 : 8[3000] -> 9[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 00/0 : 9[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 01/0 : 7[3000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 8[3000] -> 9[3000] [send] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 01/0 : 8[3000] -> 9[3000] [send] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 00/0 : 3[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 01/0 : 3[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 00/0 : 6[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 01/0 : 6[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 01/0 : 9[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 5[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 01/0 : 3[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 4[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 00/0 : 7[3000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 01/0 : 7[3000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 01/0 : 4[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Connected all rings
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 01/0 : 5[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 01/0 : 3[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 3[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 00/0 : 2[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 9[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 01/0 : 9[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 5[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Connected all rings
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 8[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 00/0 : 8[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 2[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 01/0 : 1[3000] -> 9[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 4[3000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 01/0 : 5[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 1[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 1[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 00/0 : 0[3000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 00/0 : 4[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 01/0 : 7[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 4[3000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 5[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 5[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 8[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 8[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 0[3000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 7[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 01/0 : 5[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 1[3000] -> 9[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Channel 00/0 : 6[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 00/0 : 4[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 01/0 : 8[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 00/0 : 7[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 00/0 : 9[3000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Channel 01/0 : 7[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Channel 01/0 : 8[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Channel 01/0 : 3[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Channel 00/0 : 9[3000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 01/0 : 3[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO Connected all trees
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 00/0 : 7[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 01/0 : 7[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1210:31092:31165 [0] NCCL INFO comm 0x1540140090d0 rank 9 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Channel 00/0 : 6[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Channel 01/0 : 4[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO Connected all trees
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1209:30977:31051 [0] NCCL INFO comm 0x14c0800090d0 rank 8 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1206:31134:31211 [0] NCCL INFO comm 0x14ad740090d0 rank 5 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:30956:31033 [0] NCCL INFO comm 0x1523900090d0 rank 4 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO Connected all trees
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:63080:63628 [0] NCCL INFO comm 0x1504780090d0 rank 0 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:63080:63080 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:38404:38477 [0] NCCL INFO comm 0x1528680090d0 rank 1 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1208:31099:31178 [0] NCCL INFO comm 0x14611c0090d0 rank 7 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:31095:31168 [0] NCCL INFO comm 0x1497e40090d0 rank 6 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO threadThresholds 8/8/64 | 80/8/64 | 8/8/512
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:32381:32452 [0] NCCL INFO comm 0x148bfc0090d0 rank 2 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1204:31693:31756 [0] NCCL INFO comm 0x1470340090d0 rank 3 nranks 10 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:barrier after loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 151.697 seconds
[default0]:time to initialize megatron (seconds): 156.431
[default0]:[after megatron is initialized] datetime: 2023-04-19 15:33:16 
[default0]:building GPT model ...
[default0]:[2023-04-19 15:33:16,590] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-04-19 15:33:16,591] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-19 15:33:16,591] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 11.86 GB, percent = 2.4%
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:n2gpu1206:31134:31212 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1202:38404:38478 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1202:38404:38404 [0] NCCL INFO comm 0x1528680090d0 rank 1 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1208:31099:31180 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1208:31099:31099 [0] NCCL INFO comm 0x14611c0090d0 rank 7 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1207:31095:31169 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:31095:31095 [0] NCCL INFO comm 0x1497e40090d0 rank 6 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:63080:63629 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:32381:32453 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:32381:32381 [0] NCCL INFO comm 0x148bfc0090d0 rank 2 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1206:31134:31134 [0] NCCL INFO comm 0x14ad740090d0 rank 5 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:30956:31035 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:30956:30956 [0] NCCL INFO comm 0x1523900090d0 rank 4 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:63080:63080 [0] NCCL INFO comm 0x1504780090d0 rank 0 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1210:31092:31166 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1210:31092:31092 [0] NCCL INFO comm 0x1540140090d0 rank 9 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:Traceback (most recent call last):
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 236, in <module>
[default0]:    main()
[default0]:  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    return f(*args, **kwargs)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
[default0]:    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
[default0]:    model = get_model(model_provider_func)
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
[default0]:    model = model_provider_func(
[default0]:  File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
[default0]:    with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:    _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._configure_train_batch_size()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:    self._batch_assertion()
[default0]:  File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
[default0]:    assert train_batch == micro_batch * grad_acc * self.world_size, (
[default0]:AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
[default0]:n2gpu1204:31693:31757 [0] NCCL INFO [Service thread] Connection closed by localRank 0
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 31095) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 38404) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
[default0]:n2gpu1204:31693:31693 [0] NCCL INFO comm 0x1470340090d0 rank 3 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 63080) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 31134) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
[default0]:n2gpu1209:30977:30977 [0] NCCL INFO comm 0x14c0800090d0 rank 8 nranks 10 cudaDev 0 busId 3000 - Abort COMPLETE
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 30977) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 31099) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 32381) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 31092) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 30956) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 31693) of binary: /scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/bin/python
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:17
  host      : n2gpu1209.ab2021.local
  rank      : 8 (local_rank: 0)
  exitcode  : 1 (pid: 30977)
  error_file: /tmp/torchelastic_t10zf6xn/1234_ciz8euxe/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 349, in wrapper
    error_handler.dump_error_file(failure.error_file, failure.exitcode)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 122, in dump_error_file
    self._rm(my_error_file)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 147, in _rm
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.SignalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1205.ab2021.local
  rank      : 4 (local_rank: 0)
  exitcode  : 1 (pid: 30956)
  error_file: /tmp/torchelastic_joai3u7k/1234_szk0ok8o/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 349, in wrapper
    error_handler.dump_error_file(failure.error_file, failure.exitcode)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 122, in dump_error_file
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    self._rm(my_error_file)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 147, in _rm
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1210.ab2021.local
  rank      : 9 (local_rank: 0)
  exitcode  : 1 (pid: 31092)
  error_file: /tmp/torchelastic_sd5rbbo8/1234_qnplzx7j/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1207.ab2021.local
  rank      : 6 (local_rank: 0)
  exitcode  : 1 (pid: 31095)
  error_file: /tmp/torchelastic_x4cielpl/1234_y51nf8sz/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 349, in wrapper
WARNING:torch.distributed.elastic.multiprocessing.errors.error_handler:torch-elastic-error.json already exists and will be overwritten. Original contents:
{
  "message": {
    "message": "SignalException: Process 30969 got signal: 15",
    "extraInfo": {
      "py_callstack": "Traceback (most recent call last):\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 236    error_handler.dump_error_file(failure.error_file, failure.exitcode)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 122, in dump_error_file
, in launch_agent\n    result = agent.run()\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n    result = f(*args, **kwargs)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n    result = self._invoke_run(role)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n    time.sleep(monitor_interval)\n  File \"/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\ntorch.distributed.elastic.multiprocessing.api.Si    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 349, in wrapper
gnalException: Process 30969 got signal: 15\n",
      "timestamp": "1681909226"
    }
  }
}
    error_handler.dump_error_file(failure.error_file, failure.exitcode)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 122, in dump_error_file
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    self._rm(my_error_file)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 147, in _rm
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
    self._rm(my_error_file)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/error_handler.py", line 147, in _rm
    os.remove(my_error_file)
FileNotFoundError: [Errno 2] No such file or directory: 'torch-elastic-error.json'
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1201.ab2021.local
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 63080)
  error_file: /tmp/torchelastic_8g8zg0oo/1234_zx6971mc/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
Traceback (most recent call last):
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1203.ab2021.local
  rank      : 2 (local_rank: 0)
  exitcode  : 1 (pid: 32381)
  error_file: /tmp/torchelastic_wygkbqcp/1234_bepi695p/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1208.ab2021.local
  rank      : 7 (local_rank: 0)
  exitcode  : 1 (pid: 31099)
  error_file: /tmp/torchelastic_7vtdrlrf/1234_5kfqzgg0/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
    os.remove(my_error_file)
FileNotFoundError: [Errno 2] No such file or directory: 'torch-elastic-error.json'
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1206.ab2021.local
  rank      : 5 (local_rank: 0)
  exitcode  : 1 (pid: 31134)
  error_file: /tmp/torchelastic_as14xywh/1234_2lcd6eub/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
    os.remove(my_error_file)
FileNotFoundError: [Errno 2] No such file or directory: 'torch-elastic-error.json'
    os.remove(my_error_file)
FileNotFoundError: [Errno 2] No such file or directory: 'torch-elastic-error.json'
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:16
  host      : n2gpu1202.ab2021.local
  rank      : 1 (local_rank: 0)
  exitcode  : 1 (pid: 38404)
  error_file: /tmp/torchelastic_5sftuorv/1234_k9adn84o/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
    return _run_code(code, main_globals, None,
  File "/opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/runpy.py", line 86, in _run_code
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================
    exec(code, run_globals)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 765, in <module>
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================
    main()
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-19_15:33:17
  host      : n2gpu1204.ab2021.local
  rank      : 3 (local_rank: 0)
  exitcode  : 1 (pid: 31693)
  error_file: /tmp/torchelastic_j9myg00p/1234_b4t4elf8/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 232, in main
      pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 141, in pretrain
      model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 400, in setup_model_and_optimizer
      model = get_model(model_provider_func)
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/training.py", line 269, in get_model
      model = model_provider_func(
    File "/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/pretrain_gpt.py", line 51, in model_provider
      with deepspeed.zero.Init(data_parallel_group=mpu.get_data_parallel_group(),
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 690, in __init__
      _ds_config = deepspeed.runtime.config.DeepSpeedConfig(config_dict_or_path,
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 764, in __init__
      self._configure_train_batch_size()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 935, in _configure_train_batch_size
      self._batch_assertion()
    File "/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 883, in _batch_assertion
      assert train_batch == micro_batch * grad_acc * self.world_size, (
  AssertionError: Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 1 * 3 * 5
  
============================================================
srun: error: n2gpu1209: task 8: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=3398730.0
slurmstepd: error: *** STEP 3398730.0 ON n2gpu1201 CANCELLED AT 2023-04-19T15:33:24 ***
srun: error: n2gpu1208: task 7: Exited with exit code 1
srun: error: n2gpu1204: task 3: Exited with exit code 1
srun: error: n2gpu1207: task 6: Exited with exit code 1
srun: error: n2gpu1206: task 5: Exited with exit code 1
srun: error: n2gpu1202: task 1: Exited with exit code 1
srun: error: n2gpu1201: task 0: Exited with exit code 1
srun: error: n2gpu1205: task 4: Exited with exit code 1
srun: error: n2gpu1210: task 9: Exited with exit code 1
srun: error: n2gpu1203: task 2: Exited with exit code 1
