cpu-bind=MASK - n2gpu1201, task  0  0 [301125]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 1 --nnodes 8 --rdzv_id=1234 --rdzv_endpoint n2gpu1201:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 2 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 2 --hidden-size 8 --num-attention-heads 2 --seq-length 512 --max-position-embeddings 512 --micro-batch-size 1 --global-batch-size 64 --train-samples 10_000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --lr-warmup-samples 5 --min-lr 1e-6 --lr-decay-style cosine --lr-decay-samples 12 --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 100 --log-interval 10 --save-interval 50 --eval-interval 100 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-dist --load checkpoints/gpt2-dist --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --zero-stage 1 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1207, task  6  0 [63088]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1203, task  2  0 [66462]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1204, task  3  0 [62957]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1205, task  4  0 [62784]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1206, task  5  0 [61864]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1201, task  0  0 [301233]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1208, task  7  0 [61835]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1202, task  1  0 [373307]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:using world size: 8, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  abort_on_unmet_fused_kernel_constraints ......... False
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  bert_binary_head ................................ True
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  clip_grad ....................................... 1.0
[default0]:  codecarbon_dir .................................. None
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  curriculum_learning ............................. False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_size .............................. 4
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distributed_backend ............................. nccl
[default0]:  embed_layernorm ................................. False
[default0]:  embedding_path .................................. None
[default0]:  encoder_seq_length .............................. 512
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 100
[default0]:  eval_iters ...................................... 10
[default0]:  eval_only ....................................... None
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 100
[default0]:  ffn_hidden_size ................................. 32
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  gigaflos_no_embeds .............................. 0
[default0]:  global_batch_size ............................... 64
[default0]:  glu_activation .................................. None
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 8
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_dim ......................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  kill_switch_path ................................ None
[default0]:  kv_channels ..................................... 4
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-dist
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 10
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_level ....................................... None
[default0]:  log_level_replica ............................... None
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_params_norm ................................. False
[default0]:  log_path ........................................ None
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  loss_on_targets_only ............................ False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ 12
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 5
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_prob ....................................... 0.15
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 512
[default0]:  mean_noise_span_length .......................... None
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mmap_warmup ..................................... False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  noise_density ................................... None
[default0]:  num_attention_heads ............................. 2
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_layers ...................................... 2
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  override_lr_scheduler ........................... False
[default0]:  pad_vocab_size_to ............................... None
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  position_embedding_type ......................... PositionEmbeddingType.absolute
[default0]:  pp_partition_method ............................. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  rank ............................................ 0
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  reweight_loss_based_on_position_frequency ....... False
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-dist
[default0]:  save_interval ................................... 50
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 512
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train_iteration_range ...................... None
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  sync_tp_duplicated_parameters ................... False
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 2
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  test_weighted_split_names ....................... None
[default0]:  test_weighted_split_paths ....................... None
[default0]:  test_weighted_split_paths_path .................. None
[default0]:  test_weighted_split_splits ...................... None
[default0]:  test_weighted_split_weights ..................... None
[default0]:  tile_factor ..................................... 1
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_name_or_path .......................... None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  train_iters ..................................... None
[default0]:  train_samples ................................... 10000
[default0]:  train_tokens .................................... None
[default0]:  train_weighted_split_paths ...................... None
[default0]:  train_weighted_split_paths_path ................. None
[default0]:  universal_checkpoint ............................ False
[default0]:  use_bnb_optimizer ............................... False
[default0]:  use_checkpoint_lr_scheduler ..................... False
[default0]:  use_contiguous_buffers_in_ddp ................... False
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  valid_num_workers ............................... 2
[default0]:  valid_weighted_split_names ...................... None
[default0]:  valid_weighted_split_paths ...................... None
[default0]:  valid_weighted_split_paths_path ................. None
[default0]:  valid_weighted_split_splits ..................... None
[default0]:  valid_weighted_split_weights .................... None
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  weight_decay .................................... 0.1
[default0]:  world_size ...................................... 8
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 1
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 16
[default0]:> building GPT2BPETokenizer tokenizer ...
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]: > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=2fea893 git_branch=main ****
[default0]:> initializing torch distributed ...
[default0]:[2023-04-20 18:08:35,006] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:pretrain_gpt.py main
[default0]:WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
[default0]:> initializing tensor model parallel with size 2
[default0]:> initializing pipeline model parallel with size 1
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:> setting random seeds to 42 ...
[default0]:[2023-04-20 18:17:07,425] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:rank>0 waiting for rank 0 before loading kernels
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.158 seconds
[default0]:WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module fused_mix_prec_layer_norm_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module fused_mix_prec_layer_norm_cuda...
[default0]:rank 0 finished kernel load
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.69<0>
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.69<0>
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.70<0>
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.73<0>
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.75<0>
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.74<0>
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.74<0>
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO Using network IB
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.70<0>
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO Using network IB
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.73<0>
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO Using network IB
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.75<0>
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO Using network IB
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.72<0>
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.72<0>
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO Using network IB
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.71<0>
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.76<0>
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.71<0>
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO Using network IB
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.76<0>
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO Using network IB
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 5/1/-1->3->7
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->3
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 00/0 : 4[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 3/-1/-1->7->-1
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 00/0 : 6[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 00/0 : 5[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Trees [0] 2/6/-1->4->0 [1] -1/-1/-1->4->5
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 3[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 01/0 : 4[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Trees [0] 4/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 00/0 : 7[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 01/0 : 5[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 00/0 : 6[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 01/0 : 6[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 00/0 : 7[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 01/0 : 3[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 4[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 00/0 : 3[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 3[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 00/0 : 5[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 01/0 : 7[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 01/0 : 6[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 01/0 : 7[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 01/0 : 4[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 01/0 : 5[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 01/0 : 3[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 3[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 00/0 : 2[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Connected all rings
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 01/0 : 3[3000] -> 7[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 2[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 01/0 : 7[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 7[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 4[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 3[3000] -> 7[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 01/0 : 5[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 00/0 : 4[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 0[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 5[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 4[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Channel 00/0 : 7[3000] -> 6[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 6[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 00/0 : 6[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 00/0 : 4[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 01/0 : 6[3000] -> 5[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Channel 01/0 : 5[3000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 00/0 : 7[3000] -> 6[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 00/0 : 6[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Channel 01/0 : 5[3000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Channel 01/0 : 6[3000] -> 5[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:62802:62917 [0] NCCL INFO comm 0x146ebc0090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO Connected all trees
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:61978 [0] NCCL INFO comm 0x14cbc40090d0 rank 7 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1206:61883:61993 [0] NCCL INFO comm 0x14d03c0090d0 rank 5 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:63106:63221 [0] NCCL INFO comm 0x14bbe00090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:301267:302513 [0] NCCL INFO comm 0x1470c40090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66594 [0] NCCL INFO comm 0x147a8c0090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1204:62977:63093 [0] NCCL INFO comm 0x14bcb80090d0 rank 3 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:373477:374624 [0] NCCL INFO comm 0x147e780090d0 rank 1 nranks 8 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:barrier after loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:rank>0 done waiting for rank 0 before loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:barrier after loading kernels
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 32.346 seconds
[default0]:time to initialize megatron (seconds): 547.943
[default0]:[after megatron is initialized] datetime: 2023-04-20 18:17:39 
[default0]:building GPT model ...
[default0]:[2023-04-20 18:17:40,017] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-04-20 18:17:40,018] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-20 18:17:40,018] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 12.19 GB, percent = 2.4%
[default0]:SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
[default0]:Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=1, model=0): 2, ProcessCoord(pipe=0, data=1, model=1): 3, ProcessCoord(pipe=0, data=2, model=0): 4, ProcessCoord(pipe=0, data=2, model=1): 5, ProcessCoord(pipe=0, data=3, model=0): 6, ProcessCoord(pipe=0, data=3, model=1): 7}
[default0]:[2023-04-20 18:17:47,995] [INFO] [module.py:358:_partition_layers] Partitioning pipeline stages with method type:transformer
[default0]:stage=0 layers=9
[default0]:     0: _to_float16
[default0]:     1: EmbeddingPipe
[default0]:     2: <lambda>
[default0]:     3: ParallelTransformerLayerPipe
[default0]:     4: ParallelTransformerLayerPipe
[default0]:     5: undo
[default0]:     6: MixedFusedLayerNorm
[default0]:     7: EmbeddingPipe
[default0]:     8: float16_to_fp32
[default0]:  loss: CrossEntropy
[default0]:[2023-04-20 18:17:48,039] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-04-20 18:17:48,040] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-20 18:17:48,040] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 12.19 GB, percent = 2.4%
[default0]:setting training iterations to 156
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-04-20 18:17:48,041] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 1/-1/-1->3->-1
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 1/-1/-1->3->-1
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 00/0 : 3[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Trees [0] 1/3/-1->2->0 [1] -1/-1/-1->2->1
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 00/0 : 3[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 01/0 : 3[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 01/0 : 3[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 00/0 : 3[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 01/0 : 3[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 00/0 : 3[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 01/0 : 3[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Connected all rings
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO Connected all trees
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1208:61853:62005 [0] NCCL INFO comm 0x14cb840090d0 rank 3 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374651 [0] NCCL INFO comm 0x147e300090d0 rank 0 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1204:62977:63116 [0] NCCL INFO comm 0x14bc740090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:63106:63246 [0] NCCL INFO comm 0x14bba00090d0 rank 3 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1206:61883:62010 [0] NCCL INFO comm 0x14d0000090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:62802:62941 [0] NCCL INFO comm 0x146e780090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:301267:302609 [0] NCCL INFO comm 0x14708c0090d0 rank 0 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Launch mode Parallel
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66610 [0] NCCL INFO comm 0x147a4c0090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default0]:Building extension module utils...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module utils...
[default0]:[2023-04-20 18:17:50,953] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-04-20 18:17:50,954] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-04-20 18:17:50,955] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2023-04-20 18:17:50,955] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-04-20 18:17:50,955] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-04-20 18:17:50,955] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[default0]:[2023-04-20 18:17:50,955] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[default0]:[2023-04-20 18:17:50,955] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[default0]:[2023-04-20 18:17:50,955] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-04-20 18:17:50,955] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Time to load utils op: 0.6474616527557373 seconds
[default0]:Rank: 1 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default0]:Building extension module utils...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.5601382255554199 seconds
[default0]:Rank: 0 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default0]:Building extension module utils...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.5611705780029297 seconds
[default0]:Rank: 5 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 3.344175100326538 seconds
[default0]:Rank: 4 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 3.3405568599700928 seconds
[default0]:Rank: 6 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 3.6558821201324463 seconds
[default0]:Rank: 2 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 4.63575553894043 seconds
[default0]:Rank: 3 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Time to load utils op: 5.324449300765991 seconds
[default0]:Rank: 7 partition count [4, 4, 4] and sizes[(51520, False), (128, False), (42, False)] 
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0006349086761474609 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0006237030029296875 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0012636184692382812 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.000985860824584961 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.001123666763305664 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0007648468017578125 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0006928443908691406 seconds
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:[2023-04-20 18:17:56,580] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-04-20 18:17:56,581] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-20 18:17:56,581] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 12.28 GB, percent = 2.4%
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:[2023-04-20 18:17:56,621] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-04-20 18:17:56,622] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-20 18:17:56,622] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 12.28 GB, percent = 2.4%
[default0]:[2023-04-20 18:17:56,622] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[default0]:[2023-04-20 18:17:56,642] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-04-20 18:17:56,643] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-20 18:17:56,643] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 12.28 GB, percent = 2.4%
[default0]:[2023-04-20 18:17:56,644] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-04-20 18:17:56,644] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-04-20 18:17:56,644] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x14713f1dddb0>
[default0]:[2023-04-20 18:17:56,644] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-04-20 18:17:56,644] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[default0]:[2023-04-20 18:17:56,644] [INFO] [config.py:957:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-04-20 18:17:56,644] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-04-20 18:17:56,644] [INFO] [config.py:957:print]   amp_enabled .................. False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   amp_params ................... False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x14713f064eb0>
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   communication_data_type ...... None
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-04-20 18:17:56,645] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   disable_allgather ............ False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   dump_state ................... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   fp16_enabled ................. True
[default0]:[2023-04-20 18:17:56,646] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-04-20 18:17:56,647] [INFO] [config.py:957:print]   global_rank .................. 0
[default0]:[2023-04-20 18:17:56,647] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[default0]:[2023-04-20 18:17:56,647] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 16
[default0]:[2023-04-20 18:17:56,647] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[default0]:[2023-04-20 18:17:56,647] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 4096
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   loss_scale ................... 0
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   memory_breakdown ............. False
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-04-20 18:17:56,725] [INFO] [config.py:957:print]   optimizer_name ............... None
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   optimizer_params ............. None
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   pld_enabled .................. False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   pld_params ................... False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   prescale_gradients ........... False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   scheduler_name ............... None
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   scheduler_params ............. None
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   sparse_attention ............. None
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   steps_per_print .............. 2000
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   train_batch_size ............. 64
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   world_size ................... 4
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[default0]:[2023-04-20 18:17:56,726] [INFO] [config.py:957:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[default0]:[2023-04-20 18:17:56,727] [INFO] [config.py:957:print]   zero_enabled ................. True
[default0]:[2023-04-20 18:17:56,727] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-04-20 18:17:56,727] [INFO] [config.py:957:print]   zero_optimization_stage ...... 1
[default0]:[2023-04-20 18:17:56,727] [INFO] [config.py:943:print_user_config]   json = {
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "train_batch_size": 64, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 1
[default0]:    }, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 12
[default0]:    }, 
[default0]:    "steps_per_print": 2.000000e+03, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0055484771728515625 seconds
[default0]:[2023-04-20 18:17:56,732] [INFO] [engine.py:81:__init__] CONFIG: micro_batches=16 micro_batch_size=1
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Connected all rings
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO Connected all trees
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66689 [0] NCCL INFO comm 0x147a240090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:62802:63010 [0] NCCL INFO comm 0x146e4c0090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1208:61853:62072 [0] NCCL INFO comm 0x14cb580090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1206:61883:62078 [0] NCCL INFO comm 0x14cfd40090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:63106:63316 [0] NCCL INFO comm 0x14bb780090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1204:62977:63184 [0] NCCL INFO comm 0x14bc480090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:302705 [0] NCCL INFO comm 0x1470600090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:373477:374726 [0] NCCL INFO comm 0x147e100090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-20 18:17:57,645] [INFO] [engine.py:136:__init__] RANK=1 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=206760 (0.207M) TOTAL_PARAMS=413520 (0.414M) UNIQUE_PARAMS=413520 (0.414M)
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-20 18:17:57,645] [INFO] [engine.py:136:__init__] RANK=0 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=206760 (0.207M) TOTAL_PARAMS=413520 (0.414M) UNIQUE_PARAMS=413520 (0.414M)
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file checkpoints/gpt2-dist 
[default0]:    will not load any checkpoints and will start from random
[default0]:[2023-04-20 18:17:57,656] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-dist/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:time (ms) | load-checkpoint: 14.18
[default0]:estimated model parameters: 0.00041352
[default0]:estimated model parameters without embeddings: 1.872e-06
[default0]:/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-BigScience/megatron/utils.py:349: UserWarning: Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings
[default0]:  warnings.warn("Parameter count with the embeddings will be inaccurate with PP > 1, as the first and last stage hold several copies of the embeddings")
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-04-20 18:17:58 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      10000
[default0]:    validation: 1280
[default0]:    test:       640
[default0]:> building train, validation, and test datasets for GPT ...
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.043571 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9690) total of 9690 documents
[default0]:    validation:
[default0]:     document indices in [9690, 9990) total of 300 documents
[default0]:    test:
[default0]:     document indices in [9990, 10000) total of 10 documents
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Trees [0] 1/3/-1->2->0 [1] -1/-1/-1->2->1
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 1/-1/-1->3->-1
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 00/0 : 3[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 00/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 01/0 : 3[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 00/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 00/0 : 3[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 01/0 : 3[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 01/0 : 1[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 01/0 : 2[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 01/0 : 3[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 01/0 : 1[3000] -> 3[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 00/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Channel 00/0 : 3[3000] -> 2[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 01/0 : 2[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:63106:63319 [0] NCCL INFO comm 0x14bb640090d0 rank 3 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:301267:302710 [0] NCCL INFO comm 0x1470540090d0 rank 0 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:62802:63013 [0] NCCL INFO comm 0x146e3c0090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66692 [0] NCCL INFO comm 0x147a100090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1207:63106:63323 [0] NCCL INFO comm 0x14bb580090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1203:66480:66696 [0] NCCL INFO comm 0x147a0c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1205:62802:63017 [0] NCCL INFO comm 0x146e2c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:302714 [0] NCCL INFO comm 0x1470480090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_10000ns_512sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.102 seconds
[default0]:    total number of samples: 56335
[default0]:    total number of epochs: 1
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_1280ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_1280ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_1280ns_512sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.035 seconds
[default0]:    total number of samples: 1830
[default0]:    total number of epochs: 1
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_512sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_512sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_512sl_42s_shuffle_idx.npy
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:    loaded indexed file in 0.116 seconds
[default0]:    total number of samples: 700
[default0]:    total number of epochs: 11
[default0]:> finished creating GPT datasets ...
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Connected all rings
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO Connected all trees
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1208:61853:62075 [0] NCCL INFO comm 0x14cb540090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1206:61883:62081 [0] NCCL INFO comm 0x14cfc00090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Channel 00/02 :    0   1
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Channel 01/02 :    0   1
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:63106:63327 [0] NCCL INFO comm 0x14bb540090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:373477:374729 [0] NCCL INFO comm 0x147dfc0090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Channel 00/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[3000] [send] via NET/IB/0
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Channel 01/0 : 1[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:301267:302718 [0] NCCL INFO comm 0x1470380090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1205:62802:63021 [0] NCCL INFO comm 0x146e300090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1204:62977:63187 [0] NCCL INFO comm 0x14bc380090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1203:66480:66700 [0] NCCL INFO comm 0x1479f80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO Launch mode Parallel
[default0]:time (ms) | model-and-optimizer-setup: 17712.78 | train/valid/test-data-iterators-setup: 4082.99
[default0]:[after dataloaders are built] datetime: 2023-04-20 18:18:08 
[default0]:done with setup ...
[default0]:training ...
[default0]:Number of parameters: [tensor rank - pipeline rank] w/ and w/o embeddings:
[default0]:[000-000] 0.0004B / 0.0000B
[default0]:[001-000] 0.0004B / 0.0000B
[default0]:[before the start of training step] datetime: 2023-04-20 18:18:09 
[default0]:[2023-04-20 18:18:09,077] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[default0]:[2023-04-20 18:18:09,078] [INFO] [checkpointing.py:530:forward] ----Partition Activations True, CPU CHECKPOINTING False
[default0]:[2023-04-20 18:18:09,078] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 2 total layers
[default0]:[2023-04-20 18:18:09,078] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[default0]:[2023-04-20 18:18:09,078] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1202:373477:374738 [0] NCCL INFO comm 0x147dd40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1206:61883:62088 [0] NCCL INFO comm 0x14cf980090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1204:62977:63194 [0] NCCL INFO comm 0x14bc140090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Connected all rings
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO Connected all trees
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1208:61853:62082 [0] NCCL INFO comm 0x14cb240090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1207:63106:63742 [0] NCCL INFO comm 0x14bae80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1205:62802:63436 [0] NCCL INFO comm 0x146dd40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1201:301267:303173 [0] NCCL INFO comm 0x146fdc0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1203:66480:67115 [0] NCCL INFO Connected all rings
[default0]:n2gpu1203:66480:67115 [0] NCCL INFO Connected all trees
[default0]:n2gpu1203:66480:67115 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1203:66480:67115 [0] NCCL INFO comm 0x1479a80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:[Rank 1] (after 10 iterations) memory (MB) | allocated: 101.77734375 | max allocated: 177.1083984375 | reserved: 184.0 | max reserved: 184.0
[default0]:[Rank 0] (after 10 iterations) memory (MB) | allocated: 101.77734375 | max allocated: 177.1083984375 | reserved: 184.0 | max reserved: 184.0
[default0]: iteration       10/     156 | consumed samples:          640 | consumed tokens:       327680 | elapsed time per iteration (s): 5.69 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082923E+01 | loss scale: 4096.0 | grad norm: 0.278 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 11.241 | TFLOPs: 0.00 |
[default0]: iteration       20/     156 | consumed samples:         1280 | consumed tokens:       655360 | elapsed time per iteration (s): 4.98 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082914E+01 | loss scale: 4096.0 | grad norm: 0.274 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.861 | TFLOPs: 0.00 |
[default0]: iteration       30/     156 | consumed samples:         1920 | consumed tokens:       983040 | elapsed time per iteration (s): 5.22 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082926E+01 | loss scale: 4096.0 | grad norm: 0.276 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.269 | TFLOPs: 0.00 |
[default0]: iteration       40/     156 | consumed samples:         2560 | consumed tokens:      1310720 | elapsed time per iteration (s): 5.13 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082896E+01 | loss scale: 4096.0 | grad norm: 0.284 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.470 | TFLOPs: 0.00 |
[default0]: iteration       50/     156 | consumed samples:         3200 | consumed tokens:      1638400 | elapsed time per iteration (s): 5.05 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082906E+01 | loss scale: 4096.0 | grad norm: 0.289 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.663 | TFLOPs: 0.00 |
[default0]:saving checkpoint at iteration      50 to checkpoints/gpt2-dist
[default0]:[2023-04-20 18:22:29,873] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_01-model_01-model_states.pt...
[default0]:[2023-04-20 18:22:29,876] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_01-model_01-model_states.pt.
[default0]:[2023-04-20 18:22:29,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_03-model_01-model_states.pt...
[default0]:[2023-04-20 18:22:29,879] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_03-model_01-model_states.pt.
[default0]:[2023-04-20 18:22:29,879] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_04-model_01-model_states.pt...
[default0]:[2023-04-20 18:22:29,882] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_04-model_01-model_states.pt.
[default0]:[2023-04-20 18:22:29,882] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_06-model_01-model_states.pt...
[default0]:[2023-04-20 18:22:29,884] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_06-model_01-model_states.pt.
[default0]:[2023-04-20 18:22:29,884] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: checkpoints/gpt2-dist/global_step50/mp_rank_01_model_states.pt
[default0]:[2023-04-20 18:22:29,884] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/mp_rank_01_model_states.pt...
[default0]:[2023-04-20 18:22:29,886] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/mp_rank_01_model_states.pt.
[default0]:[2023-04-20 18:22:29,829] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!
[default0]:[2023-04-20 18:22:29,873] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_01-model_00-model_states.pt...
[default0]:[2023-04-20 18:22:29,876] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_01-model_00-model_states.pt.
[default0]:[2023-04-20 18:22:29,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_03-model_00-model_states.pt...
[default0]:[2023-04-20 18:22:29,879] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_03-model_00-model_states.pt.
[default0]:[2023-04-20 18:22:29,879] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_04-model_00-model_states.pt...
[default0]:[2023-04-20 18:22:29,881] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_04-model_00-model_states.pt.
[default0]:[2023-04-20 18:22:29,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/layer_06-model_00-model_states.pt...
[default0]:[2023-04-20 18:22:29,884] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/layer_06-model_00-model_states.pt.
[default0]:[2023-04-20 18:22:29,884] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-dist/global_step50/mp_rank_00_model_states.pt
[default0]:[2023-04-20 18:22:29,884] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/mp_rank_00_model_states.pt...
[default0]:[2023-04-20 18:22:29,886] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/mp_rank_00_model_states.pt.
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt...
[default0]:[2023-04-20 18:22:30,053] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:22:30,053] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:22:30,053] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt...
[default0]:[2023-04-20 18:22:30,053] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:22:30,053] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:22:30,053] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt...
[default0]:[2023-04-20 18:22:30,066] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:22:30,066] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:22:30,066] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:22:30,053] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:22:30,057] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:22:30,057] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:22:30,057] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-20 18:22:30,049] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:22:30,055] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:22:30,055] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:22:30,055] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-20 18:22:30,158] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:22:30,158] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:[2023-04-20 18:22:30,108] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:22:30,108] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_2_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:22:30,108] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:  successfully saved checkpoint at iteration      50 to checkpoints/gpt2-dist
[default0]:[2023-04-20 18:22:31,059] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:22:31,059] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step50/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:22:31,059] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!
[default0]:time (ms) | save-checkpoint: 1334.38
[default0]: iteration       60/     156 | consumed samples:         3840 | consumed tokens:      1966080 | elapsed time per iteration (s): 5.21 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082919E+01 | loss scale: 4096.0 | grad norm: 0.266 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.274 | TFLOPs: 0.00 |
[default0]: iteration       70/     156 | consumed samples:         4480 | consumed tokens:      2293760 | elapsed time per iteration (s): 5.01 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082943E+01 | loss scale: 4096.0 | grad norm: 0.273 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.785 | TFLOPs: 0.00 |
[default0]: iteration       80/     156 | consumed samples:         5120 | consumed tokens:      2621440 | elapsed time per iteration (s): 5.24 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082930E+01 | loss scale: 4096.0 | grad norm: 0.300 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.205 | TFLOPs: 0.00 |
[default0]: iteration       90/     156 | consumed samples:         5760 | consumed tokens:      2949120 | elapsed time per iteration (s): 5.03 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082894E+01 | loss scale: 4096.0 | grad norm: 0.272 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.734 | TFLOPs: 0.00 |
[default0]: iteration      100/     156 | consumed samples:         6400 | consumed tokens:      3276800 | elapsed time per iteration (s): 4.95 | learning rate: 1.000E-06 | global batch size:    64 | lm loss: 1.082876E+01 | loss scale: 4096.0 | grad norm: 0.281 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 12.940 | TFLOPs: 0.00 |
[default0]:-----------------------------------------------------------------------------------------
[default0]:valid loss at iteration 100 | lm loss value: 1.082929E+01 | lm loss PPL: 5.047787E+04 | 
[default0]:-----------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     100 to checkpoints/gpt2-dist
[default0]:[2023-04-20 18:27:06,603] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[default0]:[2023-04-20 18:27:06,634] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_01-model_00-model_states.pt...
[default0]:[2023-04-20 18:27:06,638] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_01-model_00-model_states.pt.
[default0]:[2023-04-20 18:27:06,638] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_03-model_00-model_states.pt...
[default0]:[2023-04-20 18:27:06,641] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_03-model_00-model_states.pt.
[default0]:[2023-04-20 18:27:06,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_04-model_00-model_states.pt...
[default0]:[2023-04-20 18:27:06,644] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_04-model_00-model_states.pt.
[default0]:[2023-04-20 18:27:06,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_06-model_00-model_states.pt...
[default0]:[2023-04-20 18:27:06,649] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_06-model_00-model_states.pt.
[default0]:[2023-04-20 18:27:06,649] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-dist/global_step100/mp_rank_00_model_states.pt
[default0]:[2023-04-20 18:27:06,649] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/mp_rank_00_model_states.pt...
[default0]:[2023-04-20 18:27:06,653] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/mp_rank_00_model_states.pt.
[default0]:[2023-04-20 18:27:06,634] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_01-model_01-model_states.pt...
[default0]:[2023-04-20 18:27:06,637] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_01-model_01-model_states.pt.
[default0]:[2023-04-20 18:27:06,637] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_03-model_01-model_states.pt...
[default0]:[2023-04-20 18:27:06,640] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_03-model_01-model_states.pt.
[default0]:[2023-04-20 18:27:06,640] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_04-model_01-model_states.pt...
[default0]:[2023-04-20 18:27:06,644] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_04-model_01-model_states.pt.
[default0]:[2023-04-20 18:27:06,644] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/layer_06-model_01-model_states.pt...
[default0]:[2023-04-20 18:27:06,646] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/layer_06-model_01-model_states.pt.
[default0]:[2023-04-20 18:27:06,646] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: checkpoints/gpt2-dist/global_step100/mp_rank_01_model_states.pt
[default0]:[2023-04-20 18:27:06,646] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/mp_rank_01_model_states.pt...
[default0]:[2023-04-20 18:27:06,649] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/mp_rank_01_model_states.pt.
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:27:06,802] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:27:06,815] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:27:06,816] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_01_optim_states.pt...
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_01_optim_states.pt...
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:27:06,802] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_0_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[default0]:[2023-04-20 18:27:06,798] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_01_optim_states.pt...
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:27:06,802] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:27:06,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:06,833] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:27:06,833] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:27:06,833] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:06,854] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default0]:[2023-04-20 18:27:06,854] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default0]:[2023-04-20 18:27:06,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:06,854] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:27:06,854] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_2_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:27:06,854] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2023-04-20 18:27:07,801] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_01_optim_states.pt.
[default0]:[2023-04-20 18:27:07,801] [INFO] [engine.py:3125:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-dist/global_step100/zero_pp_rank_1_mp_rank_01_optim_states.pt
[default0]:[2023-04-20 18:27:07,802] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:time (ms) | save-checkpoint: 1298.33
[default0]:  successfully saved checkpoint at iteration     100 to checkpoints/gpt2-dist
[default0]:[exiting program at iteration 100] datetime: 2023-04-20 18:27:07 
[default0]:n2gpu1207:63106:63223 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1202:373477:374626 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO comm 0x147e780090d0 rank 1 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1202:373477:374727 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO comm 0x147e100090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1202:373477:374739 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO comm 0x147dd40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1202:373477:374730 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO comm 0x14bbe00090d0 rank 6 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1207:63106:63317 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO comm 0x14bb780090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1207:63106:63743 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO comm 0x14bae80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1207:63106:63328 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO comm 0x14bb540090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1207:63106:63324 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO comm 0x14bb580090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1207:63106:63320 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1207:63106:63106 [0] NCCL INFO comm 0x14bb640090d0 rank 3 nranks 4 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1202:373477:373477 [0] NCCL INFO comm 0x147dfc0090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:62802:62919 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO comm 0x146ebc0090d0 rank 4 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:62802:63011 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO comm 0x146e4c0090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:62802:63437 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO comm 0x146dd40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:62802:63022 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO comm 0x146e300090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:62802:63018 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO comm 0x146e2c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1205:62802:63014 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1205:62802:62802 [0] NCCL INFO comm 0x146e3c0090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:302536 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO comm 0x1470c40090d0 rank 0 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:302707 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1206:61883:61995 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO comm 0x14d03c0090d0 rank 5 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1206:61883:62079 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO comm 0x14cfd40090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1206:61883:62089 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO comm 0x14cf980090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1206:61883:62082 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1206:61883:61883 [0] NCCL INFO comm 0x14cfc00090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO comm 0x1470600090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:303174 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO comm 0x146fdc0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:302719 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO comm 0x1470380090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:302715 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO comm 0x1470480090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1201:301267:302711 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1201:301267:301267 [0] NCCL INFO comm 0x1470540090d0 rank 0 nranks 4 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1204:62977:63094 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO comm 0x14bcb80090d0 rank 3 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1204:62977:63185 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO comm 0x14bc480090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1204:62977:63195 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO comm 0x14bc140090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1204:62977:63188 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1204:62977:62977 [0] NCCL INFO comm 0x14bc380090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:66595 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1208:61853:61979 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO comm 0x147a8c0090d0 rank 2 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO comm 0x14cbc40090d0 rank 7 nranks 8 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:66690 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1208:61853:62073 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO comm 0x147a240090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:67116 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO comm 0x1479a80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:66701 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO comm 0x14cb580090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1208:61853:62083 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO comm 0x14cb240090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1208:61853:62076 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO comm 0x1479f80090d0 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:66697 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO comm 0x147a0c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:66693 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[default0]:n2gpu1208:61853:61853 [0] NCCL INFO comm 0x14cb540090d0 rank 1 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
[default0]:n2gpu1203:66480:66480 [0] NCCL INFO comm 0x147a100090d0 rank 1 nranks 4 cudaDev 0 busId 3000 - Abort COMPLETE
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'n2gpu1202.ab2021.local_373307_0' has failed to shutdown the rendezvous '1234' due to an error of type RendezvousConnectionError.
